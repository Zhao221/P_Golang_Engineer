# 上将优选电商平台

使用 Go 语言开发的电商项目，涵盖了用户管理、商品展示、收藏夹管理、订单处理、购物车操作、地址管理和 支付功能等核心模块。项目采用了成熟的技术栈，整个项目致力于提供一个稳定、易于维护的电商平台。 

# **kafka实现新增商品消息推送**

Kafka 是一个开源的分布式流处理平台，由 Apache 软件基金会开发和维护。它主要用于构建实时数据流处理应用程序，以满足高吞吐量、低延迟和高可扩展性的需求。Kafka 可以处理数百亿次的事件（如消息、日志、指标等）并将其传输到多个订阅者。**特点是高吞吐量、持久性、分布式**

想实现实现一个新增商品推送给老用户的功能，提高新商品的曝光率，在新增商品入库之后，会把新增商品的结构体序列化，然后放入kafka中，然后在从kafka中取出来，将这个产品消息存入消息表里，这样只要新增产品，用户就可以通过获取消息列表看到新产品

## **kafka应用场景**

Kafka 是一个高性能、可扩展的分布式流处理平台，它在许多不同的应用场景中都有广泛的用途。以下是一些 Kafka 的典型用途：

- 日志聚合：Kafka 可以用于收集和传输大量的日志数据，以便集中存储和处理。这有助于实现对日志数据的实时监控、分析和报告。
- 数据流处理：Kafka 可以用于构建实时数据流处理管道，以便对数据进行过滤、转换、聚合和分析等操作。这对于实时数据监控、实时报表生成和实时推荐等应用场景非常有用。
- 消息队列：Kafka 可以作为一个高性能、可扩展的消息队列系统，用于在分布式系统中传输数据。这有助于实现系统的解耦，从而提高系统的可维护性和可扩展性。
- 事件驱动架构：Kafka 可以用于构建事件驱动的微服务架构，以提高系统的解耦和可扩展性。在这种架构中，各个微服务之间通过 Kafka 传递事件，从而实现异步通信和松耦合。
- 数据同步：Kafka 可以用于实现跨系统、跨数据库的数据同步。通过将数据变更作为事件发送到 Kafka，其他系统和数据库可以订阅这些事件，并根据需要实时更新自己的数据。
- 大数据处理：Kafka 可以作为大数据处理平台（如 Hadoop、Spark 等）的数据源，提供实时或批量的数据输入。这有助于实现对大规模数据的实时或离线分析、挖掘和机器学习。
- 实时监控和报警：Kafka 可以用于实时监控系统状态、性能指标和业务指标。通过实时分析 Kafka 中的数据，可以实现对异常情况的实时检测和报警。
- 分布式事务：Kafka 可以用于支持分布式事务，在多个服务或组件之间进行协调和状态同步。通过 Kafka 传递事务状态和命令，可以实现对分布式事务的管理和控制。

这些仅仅是 Kafka 的部分用途，实际上 Kafka 在不同行业和场景下还有更多的应用。总之，Kafka 作为一个高性能、可扩展的分布式流处理平台，具有广泛的应用价值。

## kafka怎么保证消息不丢失

在Kafka中，有几个关键机制可以帮助保证消息不丢失：

1. 持久化日志：Kafka使用一种持久化日志的方式来存储消息。所有的消息都被追加到磁盘上的日志文件中，而不是立即删除或标记为已消费。这样即使发生故障，消息仍然可用。

1. 复制机制：Kafka支持将消息复制到多个副本中。每个分区都可以配置多个副本，其中一个副本被称为领导者（leader），其他副本被称为追随者（follower）。领导者负责处理读写请求，而追随者会复制领导者的数据。如果领导者故障，追随者中的一个会被选举为新的领导者，确保消息的持续可用性。

1. 同步写入：Kafka提供了同步写入和异步写入两种模式。在同步模式下，生产者在消息写入后会等待服务器的确认响应，确保消息已成功写入所有副本。只有在得到确认后，生产者才会发送下一条消息。这种方式可以确保消息的可靠性，但会增加延迟。异步模式下，生产者会尽快发送消息，而不等待确认响应，从而提高吞吐量，但可能会导致消息丢失。

1. 消费者位移提交：Kafka通过消费者位移（consumer offset）来跟踪每个消费者在分区中的位置。消费者将位移提交给Kafka，表示已经成功处理了该位移之前的所有消息。这样即使消费者重新启动或发生故障，它可以从上次提交的位移处继续消费消息，避免消息丢失。

1. **备份和容错：Kafka可以配置多个Broker来提供容错和高可用性。如果一个Broker发生故障，其他Broker可以接管它的工作，确保消息的持续传递和可用性。**

综合使用这些机制，Kafka可以提供高可靠性的消息传递服务，最大程度地避免消息丢失。但是需要注意，Kafka并不能绝对保证消息不丢失，因为在极端情况下（如多个Broker同时故障），仍然存在一定的丢失风险。因此，在设计应用程序时，需要根据实际需求和可靠性要求来选择适当的配置和策略。

Kafka 通过以下几种方式来保证消息不丢失： 1. 磁盘冗余存储：Kafka 会将消息存储在磁盘上，并且会在多台机器上做冗余存储，这样即使某台机器出现故障，消息也不会丢失。 2. 消息持久化：Kafka 会将消息持久化到磁盘上，这样即使 Kafka 服务器宕机，消息也不会丢失。 3. 消息确认机制：Kafka 提供了消息确认机制，生产者可以通过该机制确认消息是否已经被正确地发送到 Kafka 集群。 4. 副本备份：Kafka 支持副本备份，可以将消息复制到多台机器上，这样即使一台机器出现故障，其他机器上的副本仍然可以提供服务。 通过以上几种方式，Kafka 可以保证消息不丢失，从而为用户提供可靠的消息传输服务。

## broker接替工作的实现

在 Kafka 中，当一个 Broker（Kafka 服务器）失效或离线时，其他健康的 Broker 可以接替其工作，以确保消息传输和消费的连续性。这是通过以下机制来实现的：

1. 副本机制：Kafka 使用分区副本的机制来保证消息的可靠性和容错性。每个分区可以有多个副本，其中一个副本被选为领导者（Leader），其余副本为追随者（Follower）。当领导者副本失效时，一个追随者副本会被选举为新的领导者，接替失效副本的工作。
2. Controller 选举：Kafka 集群中有一个特殊的角色称为 Controller，它负责管理整个集群的状态和分区的分配。当集群中的 Broker 发生变化时，例如失效或新 Broker 加入，Controller 负责监测并触发相应的操作。当某个 Broker 失效时，Controller 会检测到并开始进行新的领导者选举，确保分区的领导者副本能够顺利切换。
3. ISR（In-Sync Replica）机制：ISR 是指与领导者副本保持同步的副本集合。当领导者副本发送消息时，它必须等待 ISR 中的所有追随者副本都成功写入消息后才会确认提交。这确保了在消息发送过程中，至少有一组健康的副本保持同步。如果一个追随者副本长时间未能跟上进度或失效，它将被移出 ISR，不再参与消息的复制和确认过程。

通过以上机制，Kafka 可以实现自动的 Broker 故障转移和副本切换，保证消息的持久性和可用性。当有 Broker 失效时，Controller 会触发新的领导者选举，将失效副本的工作接替，并确保消息的连续传输和消费。



## kafka是怎么取消息的

Kafka 是一种分布式的消息队列系统，它提供了高效的消息存储和检索功能。Kafka 使用了一种称为“拉取（pull）”的消息获取方式。 在 Kafka 中，消费者（Consumer）订阅一个或多个主题（Topic），并从 Kafka 集群中拉取该主题的消息。消费者可以根据自己的需要，按照特定的方式来处理这些消息，如存储到数据库、发送到其他系统等。 当消费者订阅一个主题时，它会向 Kafka 服务器发送一个拉取请求，请求中包含了主题名称和消息偏移量（ Offset）。Kafka 服务器收到请求后，会根据请求中的主题名称和偏移量，从存储该主题的消息日志中读取消息，并返回给消费者。 消费者可以根据需要重复拉取消息，并且可以通过更新消息偏移量来告诉 Kafka 服务器从哪里开始读取消息。这样，消费者就可以按照自己的需要来灵活地获取和处理消息，实现高效的消息处理和传输。

Kafka 是一个分布式的流处理平台，它提供了高吞吐量、可持久化、可扩展的消息发布和订阅机制。在 Kafka 中，消费者可以通过订阅一个或多个主题（topics）来消费消息。

当消息被发送到 Kafka 的主题中时，消费者可以通过订阅该主题来接收这些消息。Kafka 保留了所有已发布的消息，消费者可以随时消费这些消息，无论它们何时加入到系统中。

消费者使用拉（pull）模型从 Kafka 中获取消息。它们可以定期向 Kafka 发送拉取请求，以获取最新的消息。消费者可以指定从指定的偏移量（offset）开始拉取消息，也可以从最早的可用消息开始拉取。

当消费者拉取消息时，它们会收到一个消息集合，其中包含一个或多个消息。消费者可以按照自己的逻辑处理这些消息，例如进行业务处理、存储到数据库等。

需要注意的是，Kafka 不是一个推（push）模型，它不会直接将消息推送给消费者。相反，消费者需要主动向 Kafka 发送拉取请求以获取消息。这种模型使得消费者可以按照自己的速度消费消息，并且可以重新拉取之前未消费的消息。

总结来说，Kafka 提供了一种可靠、高吞吐量的消息传递机制，消费者通过拉取模型从 Kafka 中获取消息，并按照自己的逻辑进行处理。

## 怎么保证不消费重复消息

Kafka 使用偏移量（offset）来保证消息不会被消费重复。每个主题（topic）的每个分区（partition）中的消息都被赋予了一个唯一的偏移量，表示消息在分区中的位置。消费者可以跟踪和管理它们消费的每个分区的偏移量。

Kafka 的消费者在消费消息时会维护一个消费者组（consumer group）。消费者组中可以有多个消费者，每个消费者负责消费一个或多个分区中的消息。每个分区只能由同一个消费者组中的一个消费者进行消费。

Kafka 通过以下方式来保证不会消费重复消息：

1. 每个消息都有一个唯一的偏移量，表示该消息在分区中的位置。
1. 每个消费者组都有一个消费者组偏移量（consumer group offset），表示消费者组在每个分区上消费的偏移量。
1. 消费者组中的消费者会定期将消费的偏移量提交给 Kafka（使用`commit`操作）。
1. Kafka 会跟踪每个消费者组在每个分区上的消费偏移量。
1. 当消费者组中的消费者发起拉取请求时，Kafka 会根据消费者组的偏移量为其返回合适的消息。
1. 消费者消费消息后，可以将消费的偏移量提交给 Kafka，以便更新消费者组的偏移量。

通过这种机制，Kafka 可以确保消费者在消费过程中不会重复消费消息。消费者组中的每个消费者都会按照各自的偏移量进行消费，并且可以在消费完成后提交偏移量，以便持久化消费进度。这样即使消费者出现故障或者新的消费者加入，它们也可以根据偏移量继续消费并避免重复消费。

# **bitmap用户签到set共同关注**

- 在数据库中存了一个bool类型的字段，签到为true，不签为false，然后初始化了一个全局的定时器，每天晚上12点再将签到的用户改为false，然后每月通过bitmap去获取一个月签到的次数，bitmap存的时候有三个字段，以id为key，当前日期为offset，1为value。

```go
redis.RedisClient.SetBit(c, "Checkin"+strconv.Itoa(int(u.Id)), int64(currentTime.Day()), 1)
// key string, offset int64, value int
// github.com/redis/go-redis/v9
```

- gorm Association和Redis set

```go
redis.RedisClient.SAdd(c, "Follow:"+strconv.Itoa(int(u.Id)), userName)
```

## 实现好友共同关注具体步骤

要使用Redis Set数据结构实现好友共同关注功能，可以按照以下步骤进行：

1. 创建好友关系：在Redis中，可以使用Set数据结构来表示每个用户的好友列表。对于每个用户，创建一个Set来保存其好友的ID。可以使用Redis的命令`SADD`将好友的ID添加到对应用户的好友列表中。

   例如，假设用户A和用户B是好友，用户C和用户D是好友，可以使用以下命令来创建好友关系：
   ````
   SADD user:A:friends B
   SADD user:B:friends A
   SADD user:C:friends D
   SADD user:D:friends C
   ```

2. 获取共同关注：要获取好友的共同关注，可以使用Redis的命令`SINTER`来计算多个集合的交集。在这里，我们可以使用`SINTER`命令来计算用户A和用户B的好友列表的交集，从而获取他们的共同关注。

   例如，要获取用户A和用户B的共同关注，可以使用以下命令：
   ````
   SINTER user:A:friends user:B:friends
   ```

   这将返回一个包含用户A和用户B共同关注的集合。

3. 使用共同关注：根据具体需求，可以对获取到的共同关注进行进一步的操作。例如，可以将共同关注存储在另一个Set中，或者进行其他的数据处理和展示。

需要注意的是，以上步骤仅展示了使用Redis Set数据结构实现好友共同关注的基本思路。在实际应用中，可能还需要考虑更多的因素，例如数据的更新、缓存策略、数据结构的设计等。

## 加快获好友速度

如果共同好友数量较多，并且希望提高获取速度而减少使用循环的次数，可以考虑使用Redis的命令`SINTERSTORE`结合管道（pipeline）操作来加快获取速度。

`SINTERSTORE`命令可以将多个集合的交集存储到一个新的集合中。使用管道操作可以将多个`SINTERSTORE`命令一次性发送给Redis服务器，减少网络延迟和通信开销。

以下是使用管道操作来加快获取共同好友的示例代码：

```python
import redis

# 创建Redis连接
redis_client = redis.Redis(host='localhost', port=6379, db=0)

# 定义用户ID
user_ids = ['A', 'B', 'C', 'D']

# 创建管道
pipeline = redis_client.pipeline()

# 将多个SINTERSTORE命令添加到管道中
for i in range(len(user_ids) - 1):
    for j in range(i + 1, len(user_ids)):
        pipeline.sinterstore(f'common_friends:{user_ids[i]}_{user_ids[j]}', f'user:{user_ids[i]}:friends', f'user:{user_ids[j]}:friends')

# 执行管道操作
pipeline.execute()

# 获取共同好友
common_friends = []
for i in range(len(user_ids) - 1):
    for j in range(i + 1, len(user_ids)):
        key = f'common_friends:{user_ids[i]}_{user_ids[j]}'
        friends = redis_client.smembers(key)
        common_friends.extend(friends)

# 打印共同好友
print(common_friends)
```

在上述代码中，首先使用管道操作将多个`SINTERSTORE`命令添加到管道中，并通过一次性执行管道操作来同时获取多个共同好友集合。最后，通过遍历获取到的共同好友集合，将共同好友添加到一个列表中。

这种方式可以有效地减少与Redis服务器的通信次数，提高获取共同好友的速度。

## 使用bitmap的问题

1. 存储空间：Redis bitmap 是一种基于二进制位的数据结构，因此每个用户的签到状态需要占用一定的存储空间。如果用户数量非常大，那么存储空间可能会成为问题。
2. 性能问题：当签到用户数量非常大时，Redis bitmap 的位运算操作可能会成为性能瓶颈。
3. 数据一致性问题：如果使用 Redis 集群实现签到功能，那么需要考虑数据一致性问题。如果集群中的某个节点故障，可能会导致签到数据不一致。
4. 安全性问题：如果签到数据存储在 Redis 中，那么需要考虑安全性问题。如果 Redis 服务器被攻击，可能会导致签到数据泄露或被篡改。

# **service层使用单例模式**

`sync.Once` 是 Go 标准库中的一个类型，用于实现一次性的初始化或操作。它确保在并发环境下某个操作只会执行一次，无论有多少个 Goroutine 尝试执行它。

在 Go 项目的 service 层中使用单例模式时，通常会将 service 类型定义为一个单例对象，以确保在整个项目中只存在一个 service 实例，从而实现服务的全局访问和资源共享。描述这种设计时，可以按照以下步骤来说明：

1. 首先，介绍 service 层的作用，即封装业务逻辑和与其他层（如数据访问层）的交互。
2. 说明为什么要在 service 层使用单例模式。这通常是因为 service 层可能包含全局的配置、状态或资源，而我们希望在整个应用程序中共享这些信息。
3. 描述如何在 Go 语言中实现单例模式。这通常涉及使用 **sync.Once**类型的变量来确保实例只被创建一次，以及提供一个全局函数来访问唯一的实例。
4. 举例说明在项目中如何使用这个单例 service 对象，以及它如何满足项目需求。

以下是一个简短的描述示例：

在我们的 Go 项目中，service 层负责处理业务逻辑和与其他层（如数据访问层）的交互。为了确保整个项目中只有一个 service 实例，我们在 service 层使用了单例模式。这样，我们可以在整个项目中共享 service 实例中的配置、状态或资源。

为了实现单例模式，我们使用了 `sync.Once` 类型的变量来确保 service 实例只被创建一次，并提供了一个全局函数来访问唯一的实例。当其他模块需要使用 service 时，它们可以通过调用该全局函数来获取 service 实例，并访问其方法和属性。

这种设计允许我们在项目中方便地访问和共享 service 层的资源，从而提高了代码的可维护性和可读性。

> **以商品模块为例**

```
var ProductSrvIns *ProductSrv
var ProductSrvOnce sync.Once
type ProductSrv struct{}
func GetProductSrv() *ProductSrv {
	ProductSrvOnce.Do(func() {
		ProductSrvIns = &ProductSrv{}
	})
	return ProductSrvIns
}以这段代码为例，描述一下在service层通过sync.once使用单例模式
```

在这段代码中，我们实现了一个名为 `ProductSrv` 的 service 层结构体。该结构体用于封装产品相关的业务逻辑。我们使用单例模式来确保整个项目中只存在一个 `ProductSrv` 实例，从而实现服务的全局访问和资源共享。

1. 首先，我们定义了一个全局变量 `ProductSrvIns`，用于存储 `ProductSrv` 的唯一实例。同时，我们定义了一个 `sync.Once` 类型的变量 `ProductSrvOnce`，用于确保 `ProductSrv` 实例只被创建一次。

2. 接下来，我们定义了一个名为 `GetProductSrv` 的全局函数。该函数负责返回 `ProductSrv` 的唯一实例。在这个函数中，我们使用 `ProductSrvOnce.Do` 方法来确保传递给它的匿名函数只执行一次。在这个匿名函数中，我们创建了一个新的 `ProductSrv` 实例并将其赋值给 `ProductSrvIns`。

3. 当其他模块需要访问 `ProductSrv` 时，它们可以调用 `GetProductSrv()` 函数来获取唯一的 `ProductSrv` 实例。这样，我们确保了在整个项目中，`ProductSrv` 结构体只有一个实例。

通过在 service 层使用 `sync.Once` 实现单例模式，我们确保整个项目中只存在一个 `ProductSrv` 实例。这有助于在项目中共享服务资源和配置，使得代码更加易于维护和阅读。

# **WaitGroup+goroutine+channel**

在创建商品的时候可能会上传多张商品图片，通过WaitGroup+goroutine实现，WaitGroup在sync包，使用Add()、Done()和Wait()三个函数来实现，add就是一共执行几个协程，在每一个协程执行结束后，计数器会减一通过done实现，wait函数是等待所有协程执行完成

在 Go 中，使用 WaitGroup 和 goroutine 可以更有效地处理并发任务，例如将多张图片上传到七牛云。当你需要上传大量图片且希望加快上传速度时，可以考虑使用 WaitGroup 和 goroutine 控制并发上传。

在上传多张图片到七牛云时，可以使用 WaitGroup 开 goroutine 控制并发任务，同时还需要对并发任务进行控制，以防止过多的 goroutine 消耗系统资源。这种情况下，可以使用带缓冲的 Channel 作为并发任务的信号量，从而限制并发任务的数量。

我们使用了带缓冲的 Channel 作为信号量来限制并发任务的数量。通过设置 maxConcurrentTasks 变量，我们可以控制同时运行的 goroutine 数量。当信号量已满时，新的任务将会阻塞等待，直到有任务完成并释放信号量空位。

这种方法允许我们在利用并发提高图片上传速度的同时，避免过多的 goroutine 占用系统资源。可以根据实际情况调整 maxConcurrentTasks 的值以获得最佳性能。

```go
package main

import (
    "fmt"
    "sync"
)
func uploadToQiniu(imagePath string) {
    // 在这里实现图片上传到七牛云的逻辑
    fmt.Printf("上传图片: %s\n", imagePath)
}
func main() {
    // 假设有以下图片需要上传
    images := []string{"image1.jpg", "image2.jpg", "image3.jpg", "image4.jpg", "image5.jpg"}
    var wg sync.WaitGroup
    wg.Add(len(images))
    // 设置最大并发任务数量
    maxConcurrentTasks := 3
    semaphore := make(chan struct{}, maxConcurrentTasks)
    // 使用 goroutine 为每个图片上传任务创建一个并发执行的任务
    for _, imagePath := range images {
        // 从信号量中获取一个空位，如果信号量已满，将会阻塞等待
        semaphore <- struct{}{}

        go func(imagePath string) {
            defer wg.Done()            // 当上传完成时，通知 WaitGroup 已完成一个任务
            defer func() { <-semaphore }() // 释放信号量空位，使其他任务可以执行

            uploadToQiniu(imagePath)
        }(imagePath)
    }
    // 等待所有 goroutine 完成
    wg.Wait()
    fmt.Println("所有图片上传完成")
}
```





## HTTP协程怎么上传多张图片

使用表单（Form）提交：在HTTP请求中使用`multipart/form-data`的Content-Type，并将每张图片封装为一个表单字段。每个表单字段都有一个唯一的名称，用于在服务器端进行识别。

## go对图片是怎么编码解码的

在Go语言中使用Gin框架处理HTTP请求时，可以使用Gin框架提供的功能来编码和解码`multipart/form-data`表单类型中的图片文件。以下是一个示例代码，演示了如何使用Gin框架来处理前端通过表单上传的图片文件：

```go
package main

import (
	"fmt"
	"github.com/gin-gonic/gin"
	"log"
)

func main() {
	router := gin.Default()

	router.POST("/upload", handleUpload)

	log.Fatal(router.Run(":8080"))
}

func handleUpload(c *gin.Context) {
	// 解析表单数据
	err := c.Request.ParseMultipartForm(32 << 20) // 限制最大内存为32MB
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	// 获取文件
	file, handler, err := c.Request.FormFile("image")
	if err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}
	defer file.Close()

	// 创建保存上传文件的目标文件
	dst, err := os.Create(handler.Filename)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	defer dst.Close()

	// 将文件内容拷贝到目标文件
	if _, err := io.Copy(dst, file); err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"message": "Image uploaded successfully!"})
}
```

在上述代码中，我们使用了Gin框架创建了一个HTTP路由，并在`handleUpload`函数中处理图片上传请求。通过调用`c.Request.ParseMultipartForm`方法解析`multipart/form-data`表单数据，并使用`c.Request.FormFile`方法获取上传的图片文件。然后，创建目标文件并将文件内容拷贝到目标文件中。需要注意的是，以上示例代码仅演示了图片的上传过程，并未包含完整的错误处理和文件存储的逻辑。在实际应用中，可能需要根据具体需求进行适当的调整和扩展，例如进行文件存储位置的配置和处理其他表单字段等。同时，你也可以根据需要返回适当的JSON响应来与前端进行通信。

## 后端获取上传进度

要获取图片上传的进度，你可以结合使用Gin框架和Go语言的`net/http`包提供的功能。以下是一个示例代码，演示了如何在Gin框架中获取图片上传的进度：

```go
package main

import (
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"sync"

	"github.com/gin-gonic/gin"
)

func main() {
	router := gin.Default()

	router.POST("/upload", handleUpload)

	log.Fatal(router.Run(":8080"))
}

func handleUpload(c *gin.Context) {
	// 解析表单数据
	err := c.Request.ParseMultipartForm(32 << 20) // 限制最大内存为32MB
	if err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	// 获取文件
	file, handler, err := c.Request.FormFile("image")
	if err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}
	defer file.Close()

	// 创建保存上传文件的目标文件
	dstPath := filepath.Join("uploads", handler.Filename)
	dst, err := os.Create(dstPath)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
		return
	}
	defer dst.Close()

	// 创建一个带锁的写入器，用于计算上传进度
	progressWriter := &ProgressWriter{
		Writer: dst,
		Total:  handler.Size,
	}

	// 启动一个协程来拷贝文件内容，并计算上传进度
	wg := sync.WaitGroup{}
	wg.Add(1)
	go func() {
		defer wg.Done()
		io.Copy(progressWriter, file)
	}()

	// 等待拷贝完成
	wg.Wait()

	c.JSON(http.StatusOK, gin.H{"message": "Image uploaded successfully!"})
}

// ProgressWriter 是一个带进度的写入器
type ProgressWriter struct {
	io.Writer
	Total   int64 // 总字节数
	Written int64 // 已写入的字节数
}

// Write 实现 io.Writer 接口的 Write 方法
func (pw *ProgressWriter) Write(p []byte) (n int, err error) {
	n, err = pw.Writer.Write(p)
	pw.Written += int64(n)

	// 计算并打印上传进度
	progress := float64(pw.Written) / float64(pw.Total) * 100
	fmt.Printf("Upload progress: %.2f%%\n", progress)

	return n, err
}
```

在上述代码中，我们定义了一个`ProgressWriter`结构体，它包装了一个标准的`io.Writer`接口，并记录了已写入的字节数和总字节数。在`Write`方法中，我们首先调用底层写入器的`Write`方法写入数据，然后更新已写入的字节数，并计算并打印上传进度。

在`handleUpload`函数中，我们创建了一个带锁的`ProgressWriter`实例，并将其作为目标文件的写入器。然后，我们启动一个协程来拷贝文件内容，并在拷贝过程中计算上传进度。最后，我们等待拷贝完成，并返回上传成功的响应。

请注意，上述代码中的进度计算仅为示例目的，实际应用中你可能需要根据具体需求进行适当的修改和扩展，例如将进度信息传递给前端或记录到日志中。

## 前端获取上传速度

要获取文件上传的进度，前端可以使用JavaScript中的`XMLHttpRequest`对象来监测上传过程中的进度事件。以下是一个示例代码，演示了如何在前端使用`XMLHttpRequest`对象来获取文件上传的进度：

```javascript
// HTML 文件上传表单
<form id="uploadForm" enctype="multipart/form-data">
  <input type="file" name="image">
  <button type="submit">Upload</button>
</form>

// JavaScript 代码
<script>
  const form = document.getElementById('uploadForm');
  form.addEventListener('submit', handleUpload);

  function handleUpload(event) {
    event.preventDefault();

    const fileInput = document.querySelector('input[type="file"]');
    const file = fileInput.files[0];

    const xhr = new XMLHttpRequest();
    xhr.open('POST', '/upload');

    // 监听上传进度事件
    xhr.upload.addEventListener('progress', handleProgress);

    const formData = new FormData();
    formData.append('image', file);

    xhr.send(formData);
  }

  function handleProgress(event) {
    if (event.lengthComputable) {
      const percentage = (event.loaded / event.total) * 100;
      console.log(`Upload progress: ${percentage.toFixed(2)}%`);
    }
  }
</script>
```

在上述代码中，我们首先获取到文件上传表单和文件输入框的引用，并为表单的提交事件添加了一个事件处理函数`handleUpload`。在`handleUpload`函数中，我们创建了一个`XMLHttpRequest`对象，并使用`open`方法指定了上传的目标URL。然后，通过监听`xhr.upload`对象的`progress`事件，我们可以获取到上传进度的相关信息。在`handleProgress`函数中，我们根据`event.loaded`和`event.total`属性计算出上传的百分比，并将其打印出来。

请注意，上述代码中的进度计算仅为示例目的，你可以根据实际需求进行适当的修改和扩展，例如更新页面上的进度条或显示上传进度的文本信息。此外，还可以根据需要处理其他`XMLHttpRequest`对象的事件，如成功、失败或完成等事件。
