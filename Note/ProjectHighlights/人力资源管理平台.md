# 人力资源管理平台

**上海识装信息科技有限公司人力资源管理平台（EHR）项目详解**

**一、项目介绍**

上海识装信息科技有限公司开发的人力资源管理平台（Electronic Human Resource，简称EHR）是一个集成了先进的人力资源管理理念和技术手段的企业级解决方案。该平台以云计算为基础，结合大数据、人工智能等前沿技术，为企业提供全面、高效、智能的人力资源管理服务。通过EHR，企业能够实现对员工信息的集中管理、招聘流程的自动化、培训与发展计划的个性化、绩效评估的精准化等目标，从而提升人力资源管理的效率和质量。

**二、项目功能**

1. **员工信息管理**：集中存储员工的基本信息、教育背景、工作经历、合同信息等，支持快速查询和动态更新。
2. **招聘管理**：自动化简历筛选、面试安排、候选人追踪等功能，简化招聘流程，提高招聘效率。
3. **培训与发展**：根据员工的能力评估和职业规划，提供个性化的培训和发展计划。
4. **绩效管理**：通过设定关键绩效指标（KPIs）和持续的绩效评估，帮助企业和员工实现目标。
5. **薪酬福利管理**：灵活配置薪酬福利体系，确保公平性和竞争力。
6. **数据分析与决策支持**：通过数据分析，为企业提供人力资源方面的决策支持和战略规划。

**三、项目目的**

1. **提高人力资源管理效率**：通过自动化和智能化的手段，减少人工操作，提高管理效率。
2. **优化员工体验**：为员工提供更加便捷、个性化的服务，提升员工的满意度和忠诚度。
3. **促进企业可持续发展**：通过科学的人力资源管理和数据分析，支持企业的长期发展战略。

**四、项目背景**

随着企业规模的扩大和市场竞争的加剧，传统的人力资源管理方式已经无法满足现代企业的需求。企业需要更加高效、智能的人力资源管理工具来支持其业务发展。同时，云计算、大数据、人工智能等技术的快速发展为开发EHR提供了有力的技术支撑。上海识装信息科技有限公司凭借其在信息技术领域的深厚积累和创新精神，推出了这款人力资源管理平台，旨在帮助企业实现人力资源管理的数字化转型。

## 异步任务实现实习生表导出

### 实现方式

```go
1.创建一个异步队列的客户端，使用 tasks.GetRedis() 函数返回的 Redis 连接。
2.在函数返回之前，关闭异步队列的客户端连接。
3.将导出任务对象 exportTask 序列化为 JSON 格式的字节流。
4.创建一个新的异步任务，使用指定的队列名称 ExportQueue 和任务数据 payload。
5.将任务添加到异步队列中，并设置最大重试次数为 3 次，处理完成后消息保留时间为 2 小时。函数返回一个信息对象 info 和可能出现的错误 err。
// ExportTaskDelivery 投递导出文件消息
func ExportTaskDelivery(ctx context.Context, exportTask *ExportTask) error {
	logs.InfoCtx(ctx, "ExportTaskDelivery send Delivery %v", exportTask)
    // 1.创建一个异步队列的客户端，使用 tasks.GetRedis() 函数返回的 Redis 连接。
	client := asynq.NewClient(tasks.GetRedis())
    // 2.在函数返回之前，关闭异步队列的客户端连接。
	defer func() {
		_ = client.Close()
	}()
    // 3.将导出任务对象 exportTask 序列化为 JSON 格式的字节流。
	payload, err := json.Marshal(exportTask)
	if err != nil {
		return err
	}
    
    // 4.创建一个新的异步任务，使用指定的队列名称 ExportQueue 和任务数据 payload。
	// 走导出通用队列
	task := asynq.NewTask(ExportQueue, payload)

	// 设置发送失败则最多重试3次
	// 处理完成后消息保留2小时
    // 5.将任务添加到异步队列中，并设置最大重试次数为 3 次，处理完成后消息保留时间为 2 小时。函数返回一个信息对象 info 和可能出现的错误 err。
	info, err := client.Enqueue(task, asynq.MaxRetry(3), asynq.Retention(2*time.Hour))
	if err != nil {
		logs.ErrorCtx(ctx, err, "could not enqueue tasks: %v")
	}
	logs.InfoCtx(ctx, "enqueued tasks: id=%s queue=%s", info.ID, info.Queue)

	return nil
}
```

```go
1.创建一个新的 Excel 文件
2.在函数结束时关闭 Excel 文件，defer 语句确保在函数退出前执行
3.添加标题行到 Sheet1
4.遍历数据并将其添加到 Sheet1
5.将生成的 Excel 文件写入一个字节缓冲区，并返回缓冲区
func GenerateExcel(data [][]interface{}, tittles []interface{}) (*bytes.Buffer, error) {
	// 创建一个新的 Excel 文件
	excelCli := excelize.NewFile()
	var err error
	// 在函数结束时关闭 Excel 文件，defer 语句确保在函数退出前执行
	defer func() {
		err := excelCli.Close()
		if err != nil {
			logs.Error(err, "generate Excel err = ")
		}
	}()

	// 添加标题行到 Sheet1
	err = excelCli.SetSheetRow("Sheet1", "A1", &tittles)
	if err != nil {
		return nil, err
	}

	// 遍历数据并将其添加到 Sheet1
	for index, value := range data {
		axis := strconv.Itoa(index + 2) // 计算行号，从第二行开始
		err = excelCli.SetSheetRow("Sheet1", "A"+axis, &value)
		if err != nil {
			logs.Error(err, "set rows err = ")
			return nil, err
		}
	}

	// 将生成的 Excel 文件写入一个字节缓冲区，并返回缓冲区
	return excelCli.WriteToBuffer()
}
```



* 将导出任务加入到导出通用队列（ 设置发送失败则最多重试3次，处理完成后消息保留2小时）

```go
	err = export.ExportTaskDelivery(ctx, &export.ExportTask{
		TaskName:  export.InterApproveListExport,
		FileType:  export.FileTypeExcel,
		FilePath:  export.InterApproveListExportPath,
		FileName:  export.GetFileName("实习生转正流程列表", uInfo.UserCname),
		FileTTL:   time.Now().Add(24 * time.Hour).Unix(),
		AuthCheck: export.GetEncryptionUserId(uInfo.Id),
		UserId:    strconv.FormatInt(int64(uInfo.Id), 10),
		Params: export.InterApproveListParams{
			EmployeeId:            res.EmployeeId,
			DepartmentCode:        getRolesManagerDepartmentCode(ctx, injectPermission, res.DepartmentCode),
			ApproveStatus:         res.ApproveStatus,
			EstProbationDateStart: res.EstProbationDateStart,
			EstProbationDateEnd:   res.EstProbationDateEnd,
		},
	})
```

* 在main函数里面开了几个并发执行的函数，其中就包含了异步任务处理的函数（还包含一些处理kfk的函数）

* 从任务中提取任务消息，从注册的导出任务里获取处理函数，调用该函数处理导出任务， 如果没有注册导出任务的处理函数，则根据任务类型调用相应的默认处理函数

* 根据上下文信息中的角色信息查询该部门的实习生，然后根据excelize这个库导出数据 

  ```go
  func GenerateExcel(data [][]interface{}, tittles []interface{}) (*bytes.Buffer, error) {
  	// 1.创建一个新的 Excel 文件
  	excelCli := excelize.NewFile()
  	var err error
  	// 2.在函数结束时关闭 Excel 文件，defer 语句确保在函数退出前执行
  	defer func() {
  		err := excelCli.Close()
  		if err != nil {
  			logs.Error(err, "generate Excel err = ")
  		}
  	}()
  
  	// 3.添加标题行到 Sheet1
  	err = excelCli.SetSheetRow("Sheet1", "A1", &tittles)
  	if err != nil {
  		return nil, err
  	}
  
  	// 4.遍历数据并将其添加到 Sheet1
  	for index, value := range data {
  		axis := strconv.Itoa(index + 2) // 计算行号，从第二行开始
  		err = excelCli.SetSheetRow("Sheet1", "A"+axis, &value)
  		if err != nil {
  			logs.Error(err, "set rows err = ")
  			return nil, err
  		}
  	}
  
  	// 5.将生成的 Excel 文件写入一个字节缓冲区，并返回缓冲区
  	return excelCli.WriteToBuffer()
  }
  ```


### 第三方库

``` 
github.com/hibiken/asynq
```

是一个 Go 语言的开源库，用于处理**异步任务**（Asynchronous Tasks）。它提供了一个轻量级的、基于 Redis 的任务队列实现，用于在分布式系统中处理异步任务的分发和执行。

该库的特点包括：

1. **简单易用：** 提供简洁的 API，方便集成到 Go 项目中。
2. **基于 Redis：** 使用 Redis 作为后端存储，实现了分布式任务队列。
3. **支持任务优先级：** 可以为任务设置优先级，确保高优先级任务更早被处理。
4. **支持任务重试：** 允许配置任务的最大重试次数，处理失败的任务会自动重试。
5. **灵活的任务调度配置：** 可以根据不同的队列和任务类型进行调度配置，支持定时任务等。

```
github.com/xuri/excelize/v2
```

是 Go 语言的一个开源库，用于读写 Microsoft Excel (XLSX) 文件的工具。Excelize 提供了一种方便的方式来创建、读取和编辑 Excel 文件，支持 XLSX 格式，这是 Microsoft Excel 2007 及更高版本使用的文件格式。

以下是 Excelize 主要的特点和功能：

1. **创建 Excel 文件：** 可以轻松创建新的 Excel 文件，包括工作表、单元格、格式、样式等。
2. **读取 Excel 文件：** 支持读取现有的 Excel 文件，包括获取单元格数据、获取工作表列表等操作。
3. **编辑和修改 Excel 文件：** 提供了丰富的 API，可以修改和编辑现有的 Excel 文件，包括插入、删除、更新单元格数据等。
4. **样式和格式：** 可以设置单元格样式、字体、边框、颜色等，以美化 Excel 文件。
5. **图表和图片：** 支持在工作表中插入图表和图片。
6. **公式支持：** 可以添加和处理 Excel 公式。
7. **支持大型 Excel 文件：** Excelize 被设计为支持处理大型 Excel 文件，提供了较低的内存消耗。

**其他第三方库**

1. **excelize:**
   - 优点：
     - 支持读写 Excel 文件，功能相对丰富。
     - 语法简单，易于使用。
     - 有较好的文档和社区支持。
   - 缺点：
     - 有些功能可能相对底层，需要一些熟悉Excel格式的知识。
     - 相对于只读或只写的需求，使用它可能有点过于庞大。
2. **go-excel:**
   - 优点：
     - 提供了更高级的API，使得创建和读取 Excel 文件更加容易。
     - 对于大多数常见的用例，提供了更简洁的接口。
   - 缺点：
     - 与 excelize 相比，文档相对较少，社区支持相对较少。
3. **xlsx:**
   - 优点：
     - 简单易用，只提供了一组简单的API。
     - 轻量级，适用于简单的Excel操作。
   - 缺点：
     - 不支持一些较高级的Excel功能，比如合并单元格等。
     - 对于复杂的Excel需求，可能不够灵活。
4. **golang.org/x/text/encoding/simplifiedchinese:**
   - 优点：
     - 适用于需要处理中文字符编码的场景。
   - 缺点：
     - 仅提供了字符编码相关的功能，不是专门用于Excel的库。
5. **gotable:**
   - 优点：
     - 简化了生成Excel表格的过程。
     - 支持表格样式设置。
   - 缺点：
     - 功能相对较少，可能不适用于所有的Excel导出需求。

### why用异步实现列表导出

使用异步实现实习生列表导出有以下几个原因：

1. 提高性能：异步编程可以充分利用计算资源和IO资源，提高程序的执行效率。在实习生列表导出这个场景中，如果采用同步方式，程序需要逐个获取每个实习生的信息并进行导出，而异步方式可以同时处理多个实习生的信息，加快导出速度。
2. 改善用户体验：使用异步方式实现导出功能可以避免用户在等待导出完成时出现界面卡顿或无响应的情况。用户可以继续进行其他操作，而不必一直等待导出完成。
3. 大规模处理：当实习生列表非常大时，同步方式可能会导致内存占用过高或者超时等问题。采用异步方式可以将任务分解成多个小任务，分批处理，避免一次性处理过多数据而导致的性能问题。
4. 并发处理：异步编程可以方便地实现并发处理，即同时处理多个任务。在实习生列表导出的场景中，可以同时向多个实习生发送导出请求，并在数据准备好后进行导出操作，提高导出效率。

总而言之，使用异步实现实习生列表导出可以提高性能、改善用户体验，并且适用于大规模处理和并发处理的场景。

### 异步的场景

异步处理是指在程序中使用异步编程模型来处理任务和操作。异步处理的主要目的是提高程序的性能和响应能力，允许程序在执行耗时操作时不会被阻塞，而是可以继续执行其他任务或响应其他事件。

异步处理的常见场景包括：

1. 网络通信：在进行网络请求时，使用异步处理可以避免主线程的阻塞，允许程序同时处理其他任务或响应其他请求。
2. 文件操作：读取或写入大文件时，使用异步处理可以提高文件操作的效率，避免主线程的阻塞。
3. 数据库查询：当进行数据库查询时，使用异步处理可以允许其他任务在查询执行的同时进行，提高数据库操作的并发性。
4. 用户界面（UI）响应：在图形用户界面中，使用异步处理可以避免用户界面的冻结，保持用户界面的流畅性和响应性。

异步处理可以通过不同的编程模型和技术来实现，如回调函数、Promise、Future、async/await等。这些技术提供了处理异步任务的机制，允许开发人员以更简洁和可读的方式编写异步代码。

需要注意的是，在使用异步处理时，需要注意线程安全性、并发访问和资源管理等问题。异步处理可能引入竞态条件和死锁等并发问题，需要采取适当的同步和互斥机制来确保程序的正确性和稳定性。

## 为什么要使用异步

使用异步实现实习生列表导出的原因和异步的好处如下：

1. 提高系统响应速度：在传统的同步导出中，用户需要等待服务器处理完所有的数据后才能得到响应，这可能会花费很长时间，尤其是在处理大量数据时。而使用异步导出，用户发出导出请求后，服务器可以立即返回响应，然后在后台异步处理数据。这样，用户就不必长时间等待，提高了系统的响应速度。
2. 提高系统吞吐量：异步导出允许服务器同时处理多个请求，而不会因为某个请求的处理时间过长而阻塞其他请求。这可以提高系统的吞吐量，使其能够更高效地处理大量并发请求。
3. 降低系统负载：异步导出将数据处理任务放在后台进行，避免了大量请求同时处理时对服务器造成的压力。这有助于降低系统的负载，提高系统的稳定性和可靠性。
4. 提高用户体验：使用异步导出，用户可以在等待数据导出的同时进行其他操作，而不会因为长时间的等待而感到不满。这可以提高用户的使用体验。

总的来说，使用异步实现实习生列表导出可以提高系统的响应速度、吞吐量、稳定性和用户体验。这对于处理大量数据或需要长时间处理数据的场景来说是非常有益的。

然而，异步导出也有一些挑战和复杂性，例如需要设计和管理异步任务、处理可能的并发问题、确保数据的一致性和完整性等。因此，在选择是否使用异步导出时，需要综合考虑系统的需求和复杂性。

## 异步会出现什么问题

使用异步的方式确实可能带来一些问题，但这些问题通常都有相应的解决方案。以下是一些常见的问题及其解决方案：

1. **回调地狱（Callback Hell）**：
   问题：当使用回调函数来处理异步操作时，可能会导致多层嵌套的回调函数，使得代码难以阅读和维护。
   
   解决方案：
   - **Promises**：使用Promise链可以替代多层嵌套的回调函数，使代码更加扁平化。
   - **Async/Await**：利用ES7引入的async和await关键字，可以写出像同步代码一样的异步逻辑，进一步简化代码结构。

2. **错误处理**：
   问题：在异步代码中，错误处理变得复杂，因为传统的try-catch块无法捕获异步操作中的错误。
   
   解决方案：
   - **Promise的错误处理**：使用Promise的`.catch()`方法来捕获错误。
   - **Async/Await与try-catch**：结合使用async/await和try-catch块，可以像处理同步代码错误一样处理异步错误。

3. **资源管理**：
   问题：异步操作可能导致资源（如数据库连接、文件句柄等）的不当管理，引发资源泄露。
   
   解决方案：
   - **使用连接池**：对于数据库连接等资源，可以使用连接池来复用和管理连接。
   - **确保资源释放**：在异步操作完成后，确保正确关闭或释放资源。

4. **并发问题**：
   问题：多个异步操作可能同时访问共享资源，导致数据不一致或其他并发问题。
   
   解决方案：
   - **锁机制**：引入锁或互斥机制来确保共享资源在同一时间只被一个异步操作访问。
   - **原子操作**：设计原子操作来避免并发冲突。
   - **使用队列**：将异步操作放入队列中，按顺序执行以避免并发问题。

5. **测试和调试**：
   问题：异步代码难以测试和调试，因为执行顺序不总是直观的。
   
   解决方案：
   - **使用断言库**：针对异步代码使用专门的断言库，如`chai-as-promised`，来简化测试。
   - **日志和监控**：增加日志记录和监控来跟踪异步操作的执行和错误。
   - **使用调试工具**：利用像`async_hooks`这样的Node.js调试工具，或浏览器的开发者工具来调试异步代码。

6. **性能问题**：
   问题：大量的异步操作可能导致性能下降，尤其是在I/O密集型任务中。
   
   解决方案：
   - **限制并发数**：通过限制同时进行的异步操作数量来避免过度消耗资源。
   - **优化数据传输**：减少不必要的数据传输，使用缓存等策略来优化性能。
   - **代码优化**：对异步代码进行性能分析和优化，避免不必要的计算和内存使用。

通过合理地应用这些解决方案，可以有效地管理异步编程带来的挑战，并充分利用其提高应用程序响应性和并发性的优势。

## 异步失败解决方案

当使用异步方式将消息发送到消息队列后立即返回，并在后续异步处理中遇到失败时，可以采取以下几种处理策略：

1. **重新入队列**：
   如果消息处理失败，可以将消息重新放入队列中，等待下一次处理。这种方式可以保证消息的可靠性，确保消息最终会被处理。但需要注意的是，如果处理失败的原因是永久性的（如数据格式错误），重新入队列可能会导致无限循环。因此，应该设置重试次数限制，并在达到限制后采取其他措施（如发送错误通知）。

2. **发送失败通知**：
   当消息处理失败时，可以向发送方发送失败通知。这样发送方可以采取相应的措施，如重新发送消息、记录错误日志或通知管理员。发送失败通知可以提高系统的可靠性和可用性，但需要确保通知机制本身的可靠性。

3. **记录日志**：
   无论消息处理是否成功，都应该将相关信息记录到日志文件中。特别是当处理失败时，应该记录详细的错误信息，以便后续分析和排查问题。日志记录可以提供错误追踪和监控的能力，帮助开发人员快速定位和解决问题。

4. **使用死信队列**：
   在某些消息队列系统中，可以设置死信队列（Dead Letter Queue）。当消息处理失败且达到重试次数限制时，消息会被自动转移到死信队列中。这样可以将失败的消息与其他消息隔离开来，便于后续处理和分析。

5. **实现回滚机制**：
   如果消息处理涉及到数据库操作或其他需要保持一致性的操作，应该实现回滚机制。当消息处理失败时，可以回滚之前的操作，确保系统状态的一致性。这通常需要数据库事务的支持。

6. **监控和告警**：
   建立有效的监控和告警系统，实时监测消息队列的状态、处理速度、失败率等关键指标。当发现异常情况时，及时发出告警通知相关人员介入处理。

综上所述，处理异步消息处理失败的情况需要综合考虑多种策略，并根据具体的应用场景和需求选择合适的方案。

## 二、入离职人数柱状图统计



```go
1.权限检查
2.获取可管理的部门列表
3.获取数据库连接
4.构建月份列表
5.获取入职信息
6.获取离职信息
7.使用lodash-go库中的GroupBy函数分组统计信息
8.构建响应数据
9.遍历月份列表，为每个月构建一个 JoinAndLeaveResp 对象，其中包含月份、入职人数和离职人数。
func (l *BpLogic) GetJoinAndLeave(ctx context.Context, req types.StatisticsReq) (resp []*types.JoinAndLeaveResp, err error) {
	// 1.从上下文中获取工作台角色信息
	rolesInfo := ctx.Value(consts.WorkbenchRoleCtxKey).(types.WorkbenchRole)
	// 检查用户是否有权限
	if !rolesInfo.HashPermission() {
		return nil, ctl.NewHttpParamsError("无权限")
	}
	// 2.获取用户可管理的所有部门
	allDeps := rolesInfo.ManagerDepartmentCodeList
	code := req.Code
	// 如果指定了要搜索的部门，检查该部门是否在用户可管理的部门列表中
	// 如果不在，则返回权限错误
	// 搜索的部门和实际拥有权限的部门求交集
	if code != "" {
		if lo.IndexOf(allDeps, code) == -1 {
			return nil, ctl.NewHttpParamsError("无权限")
		}
		// 获取指定部门及其所有子部门的交集
		dpt := dcache.GetDepartmentCodeTree(ctx, true)
		allChildren := dpt.GetAllChildren(code)
		allDeps = lo.Intersect(allChildren, allDeps)
	}
	// 3.获取数据库连接
	dbConn := ehr.GetEhrDB(ctx)

	// 4.构建过去11个月的月份列表
	monthList := make([]string, 0)
	for i := 11; i > -1; i-- {
		y, m, _ := carbon.Now().SubMonthsNoOverflow(i).StartOfMonth().Date()
		monthList = append(monthList, fmt.Sprintf("%02d-%02d", y, m))
	}

	// 过去11个月的时间
	lastTime := carbon.Now().SubMonthsNoOverflow(11).StartOfMonth().Timestamp()

	// 5.获取用户入职统计信息
	deptIds := pkgDao.GetDept(ctx).Codes2Ids(allDeps)
	monthJoin, err := indDao.NewUserInductionDaoByDB(dbConn).GetJoinCountGpMonth(deptIds, lastTime)
	if err != nil {
		logs.ErrorCtx(ctx, err, "GetJoinCountGpMonth, err: %v", err)
		return nil, err
	}

	// 6..获取用户离职统计信息
	userIds := pkgDao.NewUserByDB(dbConn).GetAllUserByDepts(deptIds)
	monthLeave, err := dao.NewLeaveUserDaoByDb(dbConn).GetLeaveCountGpMonth(userIds, lastTime)
	if err != nil {
		logs.ErrorCtx(ctx, err, "GetLeaveCountGpMonth, err: %v", err)
		return nil, err
	}

	// 7.使用 lodash-go 库中的 GroupBy 函数按月份分组统计信息
	monthJoinMap := lo.GroupBy(monthJoin, func(item *indDao.MonthJoinCount) string {
		return item.Month
	})
	monthLeaveMap := lo.GroupBy(monthLeave, func(item *dao.MonthLeaveCount) string {
		return item.Month
	})

	// 8.构建响应数据
	resp = make([]*types.JoinAndLeaveResp, 0)

	for _, month := range monthList {
		resp = append(resp, &types.JoinAndLeaveResp{
			Month: month,
			Join: lo.Sum(lo.Map(monthJoinMap[month], func(item *indDao.MonthJoinCount, index int) int {
				return item.Count
			})),
			Leave: lo.Sum(lo.Map(monthLeaveMap[month], func(item *dao.MonthLeaveCount, index int) int {
				return item.Count
			})),
		})
	}
	return
}
```

## 三、同步ACL角色、EHR管理员相关用户

```bash
更新ACL中 "OKR管理员" 角色的用户
```

**使用WaitGroup+groutinue加快同步速度**

得物的EHR（Employee Human Resources）平台是一个人力资源管理软件，用于管理企业的人力资源信息、员工档案、考勤、薪酬等。ACL（Access Control List）角色是EHR平台中的一个权限管理功能，用于控制用户对系统的访问和操作。而EHR管理员是指在EHR平台中拥有管理权限的用户，通常是负责人力资源管理的员工或部门。

在得物的EHR平台中，EHR管理员和ACL角色之间存在密切的关系。具体来说，EHR管理员通常会根据其职责和需求被分配不同的ACL角色，这些角色决定了他们可以对系统进行的操作和访问的限制。例如，一些EHR管理员可能被分配为超级管理员角色，可以对系统进行全面的管理和操作，包括对其他用户的管理和分配权限；而另一些EHR管理员可能被分配为普通用户角色，只能进行有限的操作和访问。

通过ACL角色的设置和管理，得物的EHR平台可以确保只有经过授权的EHR管理员才能访问和操作相应的数据和功能，从而保护企业的敏感信息和机密数据不被泄露或滥用。同时，得物的EHR平台还可以记录和追踪EHR管理员的操作记录，以便于后续的审计和监控。

总之，得物的EHR平台中的ACL角色和EHR管理员之间的关系是一种权限管理和职责分配的关系。通过合理的ACL角色分配和管理，可以确保EHR管理员能够高效地完成其职责，同时保证系统的安全性和数据的完整性。

得物的EHR（Employee Human Resources）平台中的ACL（Access Control List）角色是一个权限管理功能，用于控制用户对系统的访问和操作。ACL角色可以定义不同的权限级别，每个级别具有不同的操作和访问限制，以保护系统的安全性和数据的完整性。

在得物的EHR平台中，ACL角色通常分为以下几种：

1. 超级管理员：具有最高权限级别，可以对系统进行全面的管理和操作，包括对其他用户的管理和分配权限。
2. 管理员：具有中等权限级别，可以对系统进行管理和操作，但不能分配其他用户的权限。
3. 普通用户：具有较低权限级别，只能进行有限的操作和访问。

通过ACL角色的设置和管理，得物的EHR平台可以确保只有经过授权的用户才能访问和操作相应的数据和功能，从而保护企业的敏感信息和机密数据不被泄露或滥用。同时，得物的EHR平台还可以记录和追踪用户的操作记录，以便于后续的审计和监控。

```go
type OkrUserDeptDataBackModel struct {
	Id                    uint64     `gorm:"column:id;primary_key;"` // 主键
	UserId                uint64     `gorm:"column:user_id"`         // 用户id
	DeptIds               string     `gorm:"column:dept_ids"`        // 部门id集合
	RoleIds               string     `gorm:"column:role_ids"`        // 角色数据集合
	IsAdmin               int        `gorm:"column:is_admin"`        // 是否超管，1为超管
	IsDelete              int        `gorm:"column:is_delete"`       // 是否删除0为未删除，1为删除
	CreateAt              time.Time  `gorm:"column:create_at"`
	UpdateAt              time.Time  `gorm:"column:update_at"`
	DeleteAt              *time.Time `gorm:"column:delete_at"`
	UserOwnDeptId         string     `gorm:"column:user_own_dept_id"`          // 用户拥有权限的去重后的部门
	AllOwnDeptId          string     `gorm:"column:all_own_dept_id"`           // 用户拥有的各种权限的综合的部门
	LeadersInChargeDeptId string     `gorm:"column:leaders_in_charge_dept_id"` // 分管总
	OkrHrbpDeptId         string     `gorm:"column:okr_hrbp_dept_id"`          // OKR HRBP
	SelfOneDeptId         string     `gorm:"column:self_one_dept_id"`          // 自己归属的一级部门
	EmployeeId            string     `gorm:"column:employee_id"`               // 用户的工号
	ManageDeptId          string     `gorm:"column:manage_dept_id"`            // 用户的工号
	AllDeptId             string     `gorm:"column:all_dept_id"`               // 自己+子部门合集
	DefaultId             int        `gorm:"column:default_id"`                // 默认展示的部门
}
var sysWait sync.WaitGroup
func (d *DataLogic) GetAclUsers(ctx context.Context) (err error) {
	// 直接调用bi端的数据
	data := eebi.GetDataFromAcl()

	if !data.Success {
		return
	}

	respData := data.Data.Data

	dataArray := lo.Chunk(respData, 1000)
	for _, loopData := range dataArray {
		sysWait.Add(1)
		newCtx := ctxkit.Clone(ctx)
		tmp := loopData
		gox.Run(func() {
			UpdateAdmin(newCtx, tmp)
		})
	}
	sysWait.Wait()
	return
}
```





## 四、从 Kafka 中消费入职用户事件消息

### 回调

```go
1.获取 LarkCallBackLogic 实例
2.解析请求体为 Map
3.处理 challenge 请求
4.处理 Lark 事件回调
// 整个处理函数的主要作用是解析飞书事件回调请求的 JSON 数据，
// 处理其中的 challenge 请求，然后将其他非 challenge 的请求内容
// 传递给 LarkCallBackLogic 实例的 EventCallback 函数进行进一步的处理
func EventCallbackHandle() gin.HandlerFunc {
	return func(ctx *gin.Context) {

		// all, err := io.ReadAll(ctx.Request.Body)
		// ctx.Request.Body.Close()
		// if err != nil {
		//	return
		// }
		//
		// logs.InfoCtx(ctx.Request.Context(), "helpdesk_callback", zap.String("body", string(all)))
		// ctx.Request.Body = io.NopCloser(bytes.NewReader(all))

		// 获取 LarkCallBackLogic 实例
		// 通过 service.GetLarkCallBackLogic() 获取 LarkCallBackLogic 的实例
		l := service.GetLarkCallBackLogic()

		// 解析请求体为 Map
		// 使用 ctx.ShouldBindBodyWith 函数将请求体解析为一个
		// map[string]interface{} 类型的变量 req。这个 map 存储了请求体的 JSON 数据
		req := map[string]interface{}{}
		if err := ctx.ShouldBindBodyWith(&req, binding.JSON); err != nil {
			ctx.JSON(http.StatusOK, gin.H{"err": err.Error()})
			return
		}

		// 处理 challenge 请求
		// 打印请求的内容日志
		// 检查请求体中是否包含了 challenge 字段，如果包含，直接返回该字段的内容作为响应。这是一种用于验证回调地址的机制。
		logs.InfoCtx(ctx, "req is %+v", req)
		if _, ok := req["challenge"]; ok {
			ctx.JSON(http.StatusOK, req)
			return
		}

		// 处理 Lark 事件回调
		// 创建一个 service.LarkEventData 类型的变量 larkReq
		// 使用 ctl.WrapHandlerPenetration 函数包装事件处理逻辑，确保异常的捕获和处理
		var larkReq *service.LarkEventData

		ctl.WrapHandlerPenetration(ctx, &larkReq, func() (resp interface{}, err error) {
			return l.EventCallback(ctx, larkReq)
		})
	}
}
```

### 生产者

```go
1.日志和幂等性检查
2.设置幂等性标识
3.事件处理
4.处理错误
5.将事件数据发送到 Kafka
6.返回
// 这段代码的主要目的是处理来自飞书的事件回调，确保在处理过程中的
// 幂等性，记录相关日志和错误，并将处理后的事件数据发送到 Kafka 主题。
func (l *LarkCallBackLogic) EventCallback(ctx context.Context, req *LarkEventData) (data interface{}, err error) {
	// 打印事件数据和事件内容的日志
	logs.InfoCtx(ctx, "EventCallback event data %+v, eventData is %+v", req, string(req.Event))
	// 创建 Redis 工具实例 redisCli
	redisCli := cache.NewRedisTools(ctx)
	// 此处做事件幂等
	// 利用 Redis 进行幂等性检查，判断当前事件是否已经处理过。如果已经处理过，直接返回，防止重复处理
	if redisCli.Exists(GetEventIdempotentKey(req.EventId())) {
		logs.InfoCtx(ctx, "EventCallback event id %v is repeat: %+v, eventData is %+v", req.EventId(), req, string(req.Event))
		return
	} else {
		// 飞书文档：
		// 事件推送
		// 推送周期和频次
		// 订阅的事件发生时，飞书将会通过 HTTP POST 请求发送 JSON 格式的事件数据到预先配置的请求地址。
		//
		// 应用收到 HTTP POST 请求后，需要在 3 秒内以 HTTP 200 状态码响应该请求。否则飞书开放平台认为本次推送失败，并以 15秒、5分钟、1小时、6小时 的间隔重新推送事件，最多重试 4 次。
		//
		// 从上述描述可以看出，事件重发的最长时间窗口约为 7.1 小时，请检查和处理在 7.1 小时内的重复事件。可以使用如下方式判断事件唯一性：
		//
		// 对于 1.0 版本的事件，通过事件结构中的 uuid 字段判断事件唯一性。
		// 对于 2.0 版本的事件，通过事件结构中的 event_id 字段判断事件唯一性。下面对事件结构进行了详细介绍。
		// 根据上述，设置过期时间为8小时
		// 如果事件没有被处理过，使用 Redis 设置幂等性标识，并设置过期时间为8小时
		redisErr := redisCli.Set(GetEventIdempotentKey(req.EventId()), 1, 8*time.Hour)
		if redisErr != nil {
			logs.ErrorCtx(ctx, err, "EventCallback set IdempotentKey fail:%v", req.EventId())
		}
	}

	// evenHandle
	// 根据事件类型使用 switch 语句，选择相应的处理逻辑。在此代码中，
	// 根据不同的飞书事件类型调用相应的处理函数。例如，处理人员入职、人员离职、
	// 人员信息修改、新建部门、删除部门、修改部门信息等不同类型的事件。
	var eventData *EventMsg
	switch req.EventType() {
	case LarkEventTypeUserCreate: // 人员入职
		eventData, err = l.processUserCreate(ctx, req)
	case LarkEventTypeUserDelete: // 人员离职
		eventData, err = l.processUserDelete(ctx, req)
	case LarkEventTypeUserUpdate: // 人员信息修改
		eventData, err = l.processUserUpdate(ctx, req)
	case LarkEventTypeDepartmentCreate: // 新建部门
		eventData, err = l.processDepartmentCreate(ctx, req)
	case LarkEventTypeDepartmentDelete: // 删除部门
		eventData, err = l.processDepartmentDelete(ctx, req)
	case LarkEventTypeDepartmentUpdate: // 修改部门信息
		eventData, err = l.processDepartmentUpdate(ctx, req)
	}

	if err != nil {
		logs.ErrorCtx(ctx, err, "EventCallback process error")
	}
	// 如果处理事件过程中出现错误，记录错误日志，并使用
	// Sentry 进行异常捕获。同时，将处理后的事件数据序列化为 JSON 格式。
	msg, err := json.Marshal(eventData)
	if err != nil {
		sentry.CaptureException(pkgErrors.Wrap(err, fmt.Sprintf("Marshal err msg is %+v", eventData)))
		return
	}
	// 使用 Kafka生产者将处理后的事件消息发送到指定的 Kafka 主题
	err = kafka.SendMessage(ctx, "default", LarkEventTopic, string(msg))
	if err != nil {
		sentry.CaptureException(pkgErrors.Wrap(err, fmt.Sprintf("SendMessage err msg is %+v", eventData)))
		return
	}

	return
}
```

### 消费者

```go
1.初始化
2.Kafka 消费者
3.消息处理回调
4.消息过滤
5.后续操作
6.处理可能的错误
// 总体而言，这段代码实现了一个从 Kafka 中消费入职用户
// 事件消息的功能，并根据消息的内容触发相应的异步操作
func (com *_partnerEntryCardSync) Run() {
	// 创建一个背景上下文ctx
	var ctx = context.Background()
	logs.Info("伙伴入职脚本消费入职用户")
	// 获取环境变量字符串 envString 和 Kafka 主题 topic
	envString := config.GetEHREnv()
	topic := lsTypes.LarkEventTopic
	// 构建 Kafka 消费者组ID groupId
	groupId := pConsts.KafkaGroupIdPartnerEntryCardSend + "-" + envString
	// 使用 Kafka 消费者组从指定的 Kafka 主题中消费消息
	// 函数 kafka.ConsumerGroup 接受一个处理消息的回调函数
	err := kafka.ConsumerGroup(ctx, "default", groupId, topic, func(msg *sarama.ConsumerMessage) error {
		// 解析 Kafka 消息中的 JSON 数据为 lsTypes.EventMsg 结构体
		var userCreateReq lsTypes.EventMsg
		// 解析相关的json数据
		if err := json.Unmarshal(msg.Value, &userCreateReq); err != nil {
			logs.Error(err, "_partnerEntryCardSync-解析发送消息失败", string(msg.Value))
			return err
		} else {
			logs.Info("解析消息成功:%+v", userCreateReq)
			// 消息过滤
			// 根据 lsTypes.EventMsg 中的 Group 和 Action 字段，进行消息过滤
			// 只有当消息属于用户组（EventGroupUser）且动作是创建（EventActionCreate）时，才会执行后续操作
			if userCreateReq.Group == lsTypes.EventGroupUser && userCreateReq.Action == lsTypes.EventActionCreate {
				// 开始推送消息
				// 使用 gox.Run 启动一个协程，执行后续的异步操作
				gox.Run(func() {
					newCtx := ctx
					// 构建 pTypes.NewPartnerSendReq 请求对象
					req := &pTypes.NewPartnerSendReq{UserId: cast.ToUint(userCreateReq.Data.Id)}
					// 调用 partnerScript.SendEntryCard2Entrants 函数，将入职卡片信息发送给入职员工
					err = partnerScript.SendEntryCard2Entrants(newCtx, req)
					if err != nil {
						logs.ErrorCtx(ctx, err, "_partnerEntryCardSync-SendEntryCard2Entrants")
					}
				})
			}
		}
		return nil
	})

	if err != nil {
		logs.Error(err, "_partnerEntryCardSync-消费kafka信息发生panic topic:"+topic)
		return
	}

}
```

