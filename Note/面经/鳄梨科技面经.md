## 短链接

短链接是一种用于缩短长链接的技术，它通过将长链接转换为短链接来减少链接的字符长度，便于分享和记忆。短链接通常由一个短的唯一标识符和一个重定向服务器组成，当用户点击短链接时，重定向服务器会将请求转发到长链接所在的原始服务器，从而实现链接的跳转。

短链接技术的优点包括：

1. 减少链接长度，便于分享和记忆。
2. 可以隐藏原始链接的真实地址，保护链接的安全性。
3. 可以通过短链接统计链接的点击次数等信息。

常见的短链接服务包括：bit.ly、goo.gl、ow.ly 等。这些服务提供了短链接生成和分析工具，可以帮助用户管理和分析短链接的使用情况。

## 一个可靠稳定的短链接服务

设计一个可靠稳定的短链接服务需要考虑多个方面，包括性能、可用性、数据一致性和安全性。以下是设计一个这样的服务的一般思路：

**1. 短链接生成与还原：**

- 实现一个短链接生成器，将长链接转换为短链接，通常使用哈希函数或自定义编码算法。
- 设计还原功能，将短链接还原为原始的长链接。

**2. 数据存储：**

- 使用可靠的数据库系统，如关系型数据库（MySQL、PostgreSQL）或 NoSQL 数据库（Redis、MongoDB），用于存储长链接与短链接之间的映射关系。
- 考虑使用缓存层来提高读取速度，减轻数据库的负载。

**3. 分布式系统：**

- 如果需要处理高并发请求，可以考虑使用分布式系统架构，将短链接映射关系存储在多个节点上，以提高性能和可用性。
- 使用负载均衡来分发请求到不同的节点。

**4. 高可用性：**

- 设计主从或主备复制，确保即使一个节点出现故障，系统依然可用。
- 使用自动故障恢复和负载均衡，以防止单点故障。

**5. 长链接有效性检查：**

- 定期检查长链接的有效性，如果链接失效，及时从系统中删除相应的短链接映射关系。

**6. 安全性：**

- 对于生成短链接的请求，要进行身份验证和授权，以确保只有授权的用户才能生成短链接。
- 防止恶意用户滥用短链接服务，可以实施限制访问速率和访问频次的策略。

**7. 数据一致性：**

- 使用事务或者分布式一致性协议来保持数据一致性，确保长链接与短链接映射的正确性。

**8. 监控和日志：**

- 实施监控和日志系统，用于追踪服务的性能、错误和异常情况。
- 实时监测系统的运行状态，以及处理潜在的问题。

**9. 扩展性：**

- 设计可扩展的架构，以便在需要时可以轻松地扩展服务的容量。

**10. 灾备和备份：**

- 设计数据备份和灾备计划，以应对数据丢失或硬件故障情况。
- 定期备份数据，确保数据可恢复。

**11. 数据加密：**

- 对于存储在数据库中的链接映射数据，可以考虑加密以增加安全性。

**12. 数据清理：**

- 定期清理不再使用的链接映射关系，以减少数据库的存储负担。

**13. 用户界面：**

- 设计用户友好的界面，使用户可以轻松生成和管理短链接。
- 提供统计和分析功能，允许用户追踪链接的点击次数和来源。

**14. 防止重复生成：**

- 确保同一个长链接不会被重复生成多个短链接，避免浪费存储空间。

总之，设计可靠稳定的短链接服务需要综合考虑性能、可用性、安全性和数据一致性等多个方面。在实际实施中，可以选择适合自己需求和技术栈的工具和技术来实现。同时，定期维护和监控服务，及时响应问题和故障，也是确保服务稳定性的关键因素。

## 进程、线程、协程的区别

进程、线程和协程是计算机科学中的重要概念，用于描述执行计算任务的不同方式。它们的主要区别如下：

1. 进程（Process）：进程是操作系统中的一个独立执行单元，具有独立的内存空间和系统资源。一个进程可以包含多个线程。进程之间相互隔离，每个进程有自己的地址空间和文件描述符，不同进程之间的通信需要使用特定的机制，如管道、套接字等。进程之间的切换开销相对较大。

1. 线程（Thread）：线程是进程内的一个执行流，共享同一进程的内存空间和系统资源。多个线程可以同时执行不同的任务，每个线程有自己的栈和局部变量，但共享进程的全局变量和堆内存。线程之间的切换相对于进程要快得多，因为线程共享了大部分上下文信息。

1. 协程（Coroutine）：协程是一种用户级的轻量级线程，由程序控制而非操作系统调度。协程可以在特定的时间点挂起、恢复和切换执行。不同于线程的抢占式调度，协程是协作式调度，需要显式地在代码中插入切换点。协程之间的切换开销非常小。协程通常用于处理高并发、高吞吐量的任务，如网络编程、事件驱动编程等。

总结来说，进程是操作系统分配资源的基本单位，线程是进程内的执行流，而协程是由程序控制的用户级线程。进程之间相互隔离，线程共享同一进程的资源，而协程通过显式的切换点实现协作式调度。不同的场景和需求可能会选择不同的执行模型来实现并发和并行的任务处理。

## 进程调度

1. 保存当前进程的上下文：操作系统会保存当前进程的寄存器状态、程序计数器和其他相关寄存器的值，以及进程的堆栈指针等信息。

2. 切换到目标进程：操作系统根据调度算法选择下一个要执行的进程，并加载该进程的上下文。这包括恢复目标进程的寄存器状态、程序计数器和堆栈指针等。

3. 更新内核数据结构：操作系统会更新内核的进程控制块（PCB）等数据结构，记录进程切换的相关信息。

4. 执行目标进程：操作系统将控制权转移到目标进程，使其开始执行。

## 线程调度

1. 保存当前线程的上下文：操作系统会保存当前线程的寄存器状态、程序计数器和其他寄存器的值，以及线程的堆栈指针等信息。

2. 切换到目标线程：操作系统根据调度算法选择下一个要执行的线程，并加载该线程的上下文。这包括恢复目标线程的寄存器状态、程序计数器和堆栈指针等。

3. 更新内核数据结构：操作系统会更新内核的线程控制块（TCB）等数据结构，记录线程切换的相关信息。

4. 执行目标线程：操作系统将控制权转移到目标线程，使其开始执行。

## 线程同步

线程同步是多线程编程中的关键问题，用于确保多个线程之间的协调和合作，以防止数据竞争和不一致的状态。以下是几种常见的线程同步方式：

1. **互斥锁（Mutex）**：
   - 互斥锁是最常见的线程同步机制。它允许多个线程并发执行，但只允许一个线程在任何时刻访问共享资源。当一个线程获取锁时，其他线程必须等待，直到该线程释放锁。
   - 互斥锁提供了一种有效的方法来保护临界区（多个线程访问的共享资源）。
2. **信号量（Semaphore）**：
   - 信号量是一个计数器，它控制对共享资源的访问。它可以用于控制多个线程对资源的同时访问。
   - 信号量可以初始化为一个非负整数，每个线程尝试访问资源时，计数器减一，当计数器为零时，其他线程必须等待，直到有一个线程释放资源并增加计数器。
3. **条件变量（Condition Variable）**：
   - 条件变量用于线程之间的协调。它允许一个线程等待某个条件满足后再继续执行。
   - 条件变量通常与互斥锁一起使用。一个线程在等待条件时可以释放互斥锁，允许其他线程进入临界区，但在条件满足后重新获取锁。
4. **屏障（Barrier）**：
   - 屏障用于在多个线程之间创建同步点。当所有线程都到达屏障时，它们可以继续执行。
   - 屏障在处理分阶段的任务或算法时很有用，因为它们确保所有线程都完成了当前阶段后才能进入下一阶段。
5. **读写锁（Read-Write Lock）**：
   - 读写锁允许多个线程同时读取共享资源，但只允许一个线程写入资源。这对于读多写少的场景非常有用，因为读操作不会互斥，但写操作需要互斥。
   - 读写锁提供了更高的并发性，因为多个线程可以同时读取数据而不会相互阻塞。
6. **自旋锁（Spin Lock）**：
   - 自旋锁是一种不让线程进入休眠状态，而是在尝试获取锁时循环忙等的锁。这在低延迟要求的场景中有用，但可能导致CPU资源浪费。
   - 自旋锁适用于短时间内能够获得锁的情况，否则会浪费大量的CPU时间。
7. **原子操作**：
   - 原子操作是一种保证不会被中断的操作，通常用于执行不可分割的操作，如增加计数器的值。
   - 原子操作可以用于实现简单的线程同步机制，但通常需要硬件支持。
8. **分布式锁**：
   - 分布式锁用于在分布式系统中实现线程同步。它们通过网络协议来确保不同节点上的线程不会同时访问共享资源。
   - 常见的分布式锁实现包括基于ZooKeeper或Redis的锁。

选择适当的线程同步方式取决于应用程序的需求和性能要求。不同的场景可能需要不同的同步机制来保护共享资源，以避免竞态条件和数据不一致性问题。

## 基于MySQL数据库表实现

通过MySQL实现分布式锁，最简单的方式可能就是直接创建一种锁表，然后通过操作该表中的数据来实现了。当锁住某个方法或者资源时，就在该表中增加一条记录，如果想要释放锁的时候就删除这条记录。

**问题**

- 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库出故障，会导致业务系统不可用

**解决方案**：可以建立两个数据库，数据之间双向同步，一旦出故障快速切换到备用库上

- 这把锁没有失效时间，一旦解锁操作失败，锁记录就会一直在数据库中，导致其他线程无法再获得锁

**解决方案**：可以做一个定时任务，每隔一段时间把数据库中的超时数据清理一遍即可

- 这把锁只能是非阻塞的，因为数据的插入操作一旦失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想获得锁就要再次触发获得锁操作

**解决方案**：加一个while循环，直到insert语句成功再返回

- 这把锁是非重入的，同一个线程在没有释放锁之前无法再再次获得该锁，因为数据已经存在了

**解决方案**：在数据库表中加个字段，记录当前获取锁机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给它就可以了

## 基于数据库排他锁实现

在查询语言后面增加“FOR UPDATE”，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该记录上增加排他锁。获得排他锁的线程即可获得分布式锁，当获取锁之后，可以执行方法的业务逻辑，执行完方法后，通过Commit()提交事务操作来释放锁。此方法可以有效得解决上面提到的无法释放锁和阻塞锁的问题。FOR UPDATE 语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，知道成功。针对锁定之后服务宕机，无法释放问题，可以使用这种方式服务宕机之后数据库会自己把锁释放掉。但是还是无法直接 解决数据库单点和可重入问题。

## 用zookeeper实现分布式锁

zookeeper是Apache软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命令注册。zookeeper的架构通过冗余服务实现高可用性。zookeeper是一种用于协调的服务分布式应用程序。zookeeper是一个分布式应用提供一致性服务的开源组件，它内部一个分层的文件系统目录树结构，它规定同一个目录下只能有一个唯一文件名。基于zookeeper实现分布式锁步骤如下：

1. 创建一个目录mylock
2. 线程A想获取锁就在mylock目录下创建临时顺序节点
3. 获取mylock目录下所有子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序序号最小，获得锁
4. 线程B获取所有节点，判断自己不是最小节点，设置监听比自己小的节点
5. 线程A处理完后，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获取锁

Apache的开源库Curator，它是一个zookeeper客户端，Curator提供的Inter-ProcessMutex是分布式锁的实现，其中，acquire()方法用于获取锁，release()方法用于释放锁。

基于zookeeper的锁与基于Redis的锁不同之处在于Lock成功之前会一直阻塞，这与单机场景中的mutex.Lock很相似。其原理也是基于临时Sequence节点和watch API，例如这里使用的是“/lock”节点。Lock会在该节点下的节点列表插入自己的值，只要节点下的子节点发生变化，就会通知所有监听该节点的程序。这时程序会检查当前节点下最小子节点的id是否与自己一致。如果一致，说明加锁成功。

这种分布式的阻塞锁比较适合分布式任务调度场景，但不适合高频次，持锁时间短的抢锁场景。基于强一致协议的锁适用于粗粒度的加锁操作。这里的粗粒度是指锁占用时间较长。

zookeeper的优点是具备高可用，可重入，阻塞锁特性，可解决失效死锁问题。zookeeper缺点：因为需要频繁地创建和删除节点，性能上不如Redis方式。

## 基于Redis的SETNX实现

Redis官方提供了一个名为RedLock的分布式锁算法来实现分布式锁。Redlock算法是Antirez（Redis作者）在单Redis节点基础上引入的高可用模式。在Redis的分布式环境中，假设有N个完全互相独立的Redis节点，有N个Redis实例上使用与在Redis单实例下相同方法获取锁和释放锁。现在假设有N个Redis主节点（大于3的奇数个），这样基本保证他们不会同时都宕掉。在获取锁和释放锁的过程中，客户端会执行以下操作：

- 获取当前Unix时间，以ms为单位

- 依次尝试从N个实例中，使用相同的key和具有唯一性的value获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间，这样可以避免客户端一直等待

- 客户端使用当前时间减去开始获取锁时间就得到获取锁使用时间。而且仅当从半数以上的Redis节点取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功

- 如果取到了锁，则key的实际有效时间等于有效时间减去获取锁所使用的时间

- 如果因为某些原因，获取锁失败（没有在半数以上的实例取到锁或者取锁时间已经超过了有效时间），则客户端应该在所有的Redis实例上进行解锁，无论Redis实例是否加锁成功。因为可以服务端响应消息丢失了但是实际成功了，毕竟多释放一次也不会有问题。

  上面5个步骤是RedLock算法的主要过程，这种分布式锁有三个重要的考量点：

  1. 互斥，只能有一个客户端获取锁
  2. 不能死锁
  3. 容错，只要大部分Redis节点创建了这把锁就可以

  实现分布式锁的另一种方式就是通过Redis等缓存系统实现。使用Redis实现分布式锁，根本原理是使用SETNX指令：

  SETNX key value

  如果key不存在，则设置key的值为value，如果key已经存在，则不执行赋值操作，并使用不同的返回值标识。

  - 使用 **SETNX + DELETE**命令实现，通过SETNX设置一个随机值，然后删除这个随机值。

  ```sql
  SETNX lock_key random_value
  // 逻辑处理
  DELETE lock_key
  // 问题：服务获取锁后，因为某种原因出现故障，则锁一直无法自动释放，从而导致死锁
  ```

  - 使用 SETNX + SETEX命令实现，通过SETNX设置一个随机值，然后通过SETEX设置超时时间，最后删除随机值

  ```SQL
  SETNX lock_key random_value
  SETEX lock_key 5 random_value // 5s超时
  // 逻辑处理
  DELETE lock_key
  // 问题：在 SETNX之后，SETEX之前服务出故障，会陷入死锁
  ```

  - 使用 SET···NX+PX命令实现，将加锁、设置超时两个步骤合并为一个原子操作

  ```sql
  SET lock_key random_value NX PX 5000 // 5s超时
  // 逻辑处理
  DELETE lock_key
  // 问题：如果锁被错误地释放（如超时），或被错误地抢占，或因Redis问题等导致锁丢失，则无法很快地感知到
  ```

  - 使用 SET Key RandomValue NX PX 命令实现，此方案比上一个方案增加了对value的检查，只解除自己加的锁，类似于CAS（Compare And Swap，比较并交换），是一种原子操作。可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定行以及中断的不可预知性产生的数据不一致问题。该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值。此处不过是先比较后删除，此方案Redis原生命令不支持，为保证原子性，需要使用Lua脚本实现，伪代码如下：

  ```
  SET lock_key random_value NX PX 5000 // 5s超时
  // 逻辑处理
  eval "ifredis.call('get',KEYS[1])==ARGV[1]then return redis.call('del',KEYS[1]) 
  else return 0 end 1" lock_key random_value
  // 此方案更加严谨，即使因为某些异常导致锁被错误地抢占，也能部分保证锁的正确释放。并且在释放锁时能检测到锁是否被错误抢占，错误释放，从而进行特殊处理。
  ```

  **注意事项：**

  - 超时时间

  1. 不能太短，否则在任务执行完成前就自动释放锁了，导致资源暴露在锁保护之外
  2. 不能太长，否则会导致以意外死锁后时间的等待，除非人为介入处理
  3. 建议根据任务内容，合理衡量超时时间，将超时时间设置为任务内容的几倍即可。如果实在无法确定而又要求比较严格，可以采用SETEX/Expire定期更新超时时间实现

  - 重试：等待次数需要参考任务执行时间

  - 与Redis事务比较，SETNX使用更为灵活方便。Multi/Exec事务的实现形式更为复杂，且部分Redis集群方案不支持Multi/Exec事务


## 使用etcd实现分布式锁

etcd是使用go语言开发的一个开源的，高可用的分布式key-value存储系统，可以用于配置共享和服务的注册和实现。etcd使用Raft算法保持了数据的 强一致性，每次操作存储到集群中的值必然是全局一致性，很容易实现分布式锁。锁服务有“保持独占” “控制时序” 两种使用方式。

“保持独占”即所有获取锁的用户最终只有一个可以得到。etcd为此提供了一套实现分布式锁原子操作CAS（Compare AND Swap，比较并交换）的API。通过设置prevExist值，可以保证在多个节点同时去创建某个目录时，只有一个成功，而成功创建的用户就可以认为是获得了锁。

“控制时序” 是指所有想要获得锁的用户都会被安排执行，但是获得锁的顺序也是全局唯一的，同时决定了执行顺序。etcd为此也提供了一套自动创建有序键的API接口，对一个目录建值时指定为POST动作，这样etcd会自动在目录下生成一个当前最大的值为键，存储这个新的值（客户端编号）。同时还可以使用API接口按顺序列出所有当前目录下的键值。此时这些键的值就是客户端的时序，也可以是代表客户端的编号。

etcd分布式锁实现原理总结如下：

- 利用租约在etcd集群中创建一个key，这个key有两种形态，存在和不存在，而这两种形态就是互斥量
- 如果key不存在，则线程创建key，成功则获取到锁，该key为存在状态
- 如果key已经存在，则线程就不能创建key，获取锁失败 





## 分布式锁的选择

| 实现方式                | 功能要求     | 实现难度              | 学习程度 | 运维成本                                                    |
| :---------------------- | ------------ | --------------------- | -------- | ----------------------------------------------------------- |
| MySQL借助表锁/行锁实现  | 满足基本要求 | 不难                  | 熟悉     | 一般 小量可以使用；大量影响现有业务。主多从架构，不方便扩容 |
| 通过zookeeper的方式实现 | 满足要求     | 要求熟悉zookeeper API | 需要学习 | 较高，需要队机器，有跨机房请求                              |
| Redis使用SET NX PX      | 满足基本要求 | 不难                  | 熟悉     | 一般，扩容方便，方便使用现有服务                            |
| 通过etcd实现            | 满足要求     | 较易                  | 熟悉     | 较高，不能增加节点来提高其性能                              |

  对锁数据的可靠性要求极高的话，那只能使用etcd或者zookeeper这种通过一致性协议保证数据可靠性的方案，但吞吐量低和较高的延迟。                                                                    						

## go的基本数据类型

1. **整数类型**：
   - `int`：根据计算机架构的不同，可以是32位或64位的有符号整数。
   - `uint`：根据计算机架构的不同，可以是32位或64位的无符号整数。
   - `int8`、`int16`、`int32`、`int64`：有符号整数，分别表示8位、16位、32位和64位整数。
   - `uint8`、`uint16`、`uint32`、`uint64`：无符号整数，分别表示8位、16位、32位和64位整数。
2. **浮点数类型**：
   - `float32`：32位单精度浮点数。
   - `float64`：64位双精度浮点数。
3. **复数类型**：
   - `complex64`：由两个32位浮点数表示的复数。
   - `complex128`：由两个64位浮点数表示的复数。
4. **布尔类型**：
   - `bool`：表示布尔值，只有两个值，`true`和`false`。
5. **字符串类型**：
   - `string`：表示文本字符串。Go的字符串是不可变的。
6. **字符类型**：
   - `rune`：表示Unicode字符，通常用于处理文本。
7. **字节类型**：
   - `byte`：表示8位无符号整数，通常用于处理原始二进制数据。
8. **指针类型**：
   - `Pointer`：表示内存地址的数据类型。可以指向其他数据类型的变量。
9. **数组类型**：
   - `array`：表示具有固定大小的数组，数组元素类型和大小在声明时确定。
10. **切片类型**：
    - `slice`：表示可变长度的序列，是对数组的一种封装，可以动态增长。
11. **映射类型**：
    - `map`：表示键值对的集合，其中每个键都是唯一的。
12. **结构体类型**：
    - `struct`：表示自定义的复合数据类型，可以包含多个字段。
13. **接口类型**：
    - `interface`：表示一组方法的集合，用于实现多态。
14. **函数类型**：
    - `func`：表示函数的类型，可以用作函数的参数或返回值。

## Casbin

Casbin 是一个轻量级的、高效的开源访问控制库，用于在应用程序中实现访问控制列表（Access Control List，ACL）和基于角色的访问控制（Role-Based Access Control，RBAC）。Casbin旨在简化和统一应用程序的访问控制实现，它支持多种编程语言，并提供了灵活的访问控制模型。

以下是 Casbin 的一些关键特点和概念：

1. **基于策略的访问控制模型**：
   - Casbin 使用一种称为 ABAC（Attribute-Based Access Control）的访问控制模型，其中访问策略基于资源、操作和主体的属性来定义。
   - 一个典型的 Casbin 策略规则由五部分组成：主体（Subject）、资源（Resource）、操作（Action）、对象（Object）、条件（Condition）。
2. **支持多种编程语言**：
   - Casbin 提供了多种编程语言的实现，包括 Go、Java、Python、Node.js、PHP、.NET 等，使其适用于不同的开发环境和技术堆栈。
3. **灵活的策略定义**：
   - Casbin 允许您根据应用程序的需求自定义策略，可以将策略存储在不同的后端数据存储中，如文件、数据库或远程服务。
4. **适用于多种场景**：
   - Casbin 可以用于各种应用场景，包括Web应用程序、微服务、API、数据库、分布式系统等，以管理和控制对资源的访问。
5. **角色和权限管理**：
   - Casbin 支持经典的 RBAC 模型，允许您定义角色和角色之间的关系，以及将角色授权给特定的资源和操作。
6. **策略生效**：
   - Casbin 允许您根据需要动态加载和更新策略，而无需重新启动应用程序。这使得在运行时进行访问控制规则的调整成为可能。
7. **可扩展性**：
   - Casbin 提供了插件系统，允许开发者实现自定义的访问控制器和策略存储，以满足特定的需求。
8. **丰富的生态系统**：
   - Casbin 生态系统包括 Casbin-HTTP-Adapter、Casbin-Persist、Casbin-RBAC、Casbin-Management-API 等相关项目，扩展了 Casbin 的功能和用途。

Casbin 是一个功能丰富的访问控制库，它可以帮助开发者轻松实现高度可定制的访问控制逻辑，从而确保应用程序的安全性和合规性。无论您是构建 Web 应用程序、微服务架构还是其他类型的应用，Casbin 都可以作为强大的访问控制工具来帮助您管理和控制资源访问。

## golang面向对象的实现

1. 封装：Go 使用大小写字母来确定字段或方法的可见性
2. 继承：结构体嵌套
3. 多态：通过接口实现

## 三次握手四次挥手

### 三次握手（Three-Way Handshake）：

1. **第一次握手**：
   - 客户端发送一个 TCP 报文，其中包含一个标志位（SYN，表示同步请求），以及一个随机的序列号（ClientSeq）。
   - 这个报文告诉服务器客户端希望建立连接。
2. **第二次握手**：
   - 服务器接收到客户端的请求后，回复一个 TCP 报文，其中包含 SYN 标志位、一个确认标志位（ACK，表示确认）和服务器的随机序列号（ServerSeq）。
   - 这个报文告诉客户端，服务器已接收到连接请求，并同意建立连接。
3. **第三次握手**：
   - 客户端接收到服务器的响应后，回复一个 TCP 报文，其中包含 ACK 标志位和客户端的序列号（ClientSeq + 1）。
   - 这个报文告诉服务器，客户端已确认服务器的响应。

在完成三次握手后，TCP 连接建立，双方可以开始进行数据传输。

### 四次挥手（Four-Way Handshake）：

1. **第一次挥手**：
   - 当客户端或服务器决定关闭连接时，发送一个 TCP 报文，其中包含 FIN 标志位（表示关闭请求）和一个用于传输数据的序列号。
   - 这个报文告诉对方，发送方希望关闭连接。
2. **第二次挥手**：
   - 接收到关闭请求的一方（不论是客户端还是服务器）发回一个报文，其中包含 ACK（表示确认）标志位，以及一个确认号，该确认号是对关闭请求序列号加一。
   - 这个报文告诉对方，它已经确认了关闭请求，并准备好关闭连接。
3. **第三次挥手**：
   - 当一方准备好关闭连接时，发送一个带有 FIN 标志位的报文。
   - 这个报文告诉对方，它已经完成了数据的发送，现在准备关闭连接。
4. **第四次挥手**：
   - 接收到关闭请求的一方发回一个 ACK 报文，确认已接收到关闭请求。这个 ACK 报文不包含 FIN 标志位。
   - 这个报文告诉对方，它已确认关闭请求。

## epoll模型

`epoll` 是 Linux 下一种高性能的 I/O 多路复用机制，它用于监听多个文件描述符上的事件，以实现非阻塞的 I/O 操作。`epoll` 的优点在于它能够处理大量并发连接，而不会因为连接数增加而导致性能下降。以下是关于 `epoll` 模型的详细介绍：

1. **`epoll` 的类型**：
   - 在 Linux 中，存在三种不同类型的 `epoll`：`epoll_create`、`epoll_create1` 和 `epoll_create1`。
   - `epoll_create` 是最早的版本，`epoll_create1` 和 `epoll_create1` 是后来的改进版本，建议使用它们，因为它们具有更好的错误处理和扩展性。
2. **`epoll` 的工作方式**：
   - `epoll` 使用一个文件描述符来表示一个 I/O 事件监听器，你可以把这个文件描述符看作是一个监听器的句柄。
   - 你可以将多个文件描述符注册到一个 `epoll` 实例上，并告诉内核要监听哪些事件（如读、写、错误等）。
3. **`epoll` 的优点**：
   - 高性能：`epoll` 可以高效地处理大量的并发连接，因为它使用了红黑树和双链表等数据结构，以及边缘触发（edge-triggered）模式。
   - 懒惰删除：`epoll` 只关心发生事件的文件描述符，不会像 `select` 和 `poll` 那样，需要不断地遍历全部文件描述符集合。
   - 支持大量文件描述符：`epoll` 可以同时监视大量文件描述符，而不受文件描述符数目的限制。
   - 可伸缩性：`epoll` 使用了多线程技术，可以充分利用多核 CPU，提高并发性能。
4. **`epoll` 的工作模式**：
   - `epoll` 有两种工作模式：边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。
   - 在 ET 模式下，只有在文件描述符状态发生变化时才会通知应用程序，这要求应用程序需要一次性将所有数据读取完，否则可能会错过事件通知。
   - 在 LT 模式下，只要文件描述符状态仍然满足监听条件，就会持续通知应用程序。
5. **`epoll` 的使用步骤**：
   - 创建一个 `epoll` 实例。
   - 使用 `epoll_ctl` 函数将文件描述符添加到 `epoll` 实例中，指定监听的事件。
   - 使用 `epoll_wait` 函数等待事件发生，并处理事件。

# **slice** 

## slice和array的区别

1. 大小固定 vs. 大小可变：
   - 数组是大小固定的，定义时需要指定数组的长度，无法动态增加或减少长度。
   - 切片是基于数组的动态长度的抽象，可以根据需要动态调整长度。
2. 值传递 vs. 引用传递：
   - 数组在赋值或传递时，会进行值拷贝，即创建一个新的数组副本。
   - 切片在赋值或传递时，只是传递了一个指向底层数组的引用，不会进行拷贝。
3. 定义方式：
   - 数组的长度是固定的，定义时需要指定长度，例如 `var arr [5]int`。
   - 切片的长度是可变的，可以通过 `make` 函数或使用切片字面量定义，例如 `s := make([]int, 5)` 或 `s := []int{1, 2, 3}`。
4. 内存分配：
   - 数组在定义时会直接分配连续的内存空间，长度固定。
   - 切片在底层依赖数组，会根据实际需要动态分配内存空间。
5. 操作和功能：
   - 数组具有一些内置的操作和功能，如遍历、排序等。
   - 切片提供了更多的操作和功能，如追加、拼接、截取等。

## slice扩容机制

扩容是为切片分配新的内存空间并复制原切片中元素的过程。在 go 语言的切片中，扩容的过程是：估计大致容量 -> 确定容量 -> 覆盖原切片 -> 完成扩容。

- 首先判断，如果新申请容量大于 2 倍的旧容量，最终容量就是新申请的容 量
- 否则判断，如果旧切片的长度小于 1024，则最终容量就是旧容量的两倍
- 否则判断，如果旧切片长度大于等于 1024，则最终容量从旧容量开始循环 增加原来的 1/4, 直到最终容量大于等于新申请的容量
- 如果最终容量计算值溢出，则最终容量就是新申请容量

## slice是否线程安全

Go 的切片（slice）类型本身并不是线程安全的。多个 goroutine 并发地对同一个切片进行读写操作可能会导致数据竞争和不确定的结果。如果需要在并发环境下安全地使用切片，可以采取以下几种方式：

1. 使用互斥锁（Mutex）或读写锁（RWMutex）来保护对切片的并发访问。在访问切片前获取锁，操作完成后释放锁，以确保同一时间只有一个 goroutine 可以访问切片。
2. 使用通道（Channel）来进行同步和通信。将切片操作封装为一个独立的 goroutine，通过通道接收和发送操作来保证对切片的顺序访问。
3. 使用原子操作（Atomic Operations）来进行原子性的读写操作。Go 提供了一些原子操作的函数，如 `atomic.AddInt32`、`atomic.LoadPointer` 等，可以确保在并发环境下对切片的操作是原子的。

## slice分配到栈上还是堆上

有可能分配到栈上，也有可能分配到栈上。当开辟切片空间较大时，会逃逸到堆上。

## 扩容过程中是否重新写入

切片的扩容， 当在尾部扩容时，追加元素，不需要重新写入；

```go
var a []int
a = append(a, 1)
```

在头部插入时；会引起内存的重分配，导致已有的元素全部重新写入；

```go
a = append([]int{0}, a...);
```

在中间插入时，会局部重新写入，如下： 使用链式操作在插入元素，在内层append函数中会创建一个临式切片，然后将a[i:]内容复制到新创建的临式切片中，再将临式切片追加至a[:i]中。

```go
a = append(a[:i], append([]int{x}, a[i:]...)...) 
a = append(a[:i], append([]int{1, 2, 3}, a[i:]...)...)//在第i个位置上插入切片
```

## go深拷贝发生在什么情况下？切片的深拷贝是怎么做的

- 深拷贝（Deep Copy）：

拷贝的是数据本身，创造一个样的新对象，新创建的对象与原对象不共享内存，新创建的对象在内存中开辟一个新的内存地址，新对象值修改时不会影响原对象值。既然内存地址不同，释放内存地址时，可分别释放。

- 浅拷贝（Shallow Copy）：

拷贝的是数据地址，只复制指向的对象的指针，此时新对象和老对象指向的内存地址是一样的，新对象值修改时老对象也会变化。释放内存地址时，同时释放内存地址。[参考来源 (opens new window)](https://blog.csdn.net/guichenglin/article/details/105601886)在go语言中值类型赋值都是深拷贝，引用类型一般都是浅拷贝：

- 值类型的数据，默认全部都是深拷贝：Array、Int、String、Struct、Float，Bool
- 引用类型的数据，默认全部都是浅拷贝：Slice，Map

对于引用类型，想实现深拷贝，不能直接 := ，而是要先开辟地址空间（new） ，再进行赋值。可以使用 copy() 函数对slice进行深拷贝，copy 不会进行扩容，当要复制的 slice 比原 slice 要大的时候，只会移除多余的。使用 append() 函数来进行深拷贝，append 会进行扩容

## copy和左值进行初始化区别

1. copy(slice2, slice1)实现的是深拷贝。拷贝的是数据本身，创造一个新对象，新创建的对象与原对象不共享内存，新创建的对象在内存中开辟一个新的内存地址，新对象值修改时不会影响原对象值。 同样的还有：遍历slice进行append赋值
2. 如slice2 := slice1实现的是浅拷贝。拷贝的是数据地址，只复制指向的对象的指针，此时新对象和老对象指向的内存地址是一样的，新对象值修改时老对象也会变化。默认赋值操作就是浅拷贝。

## slice和map的区别

Map 是一种无序的键值对的集合。Map 可以通过 key 来快速检索数据，key 类似于索引，指向数据的值。 而 Slice 是切片，可以改变长度，动态扩容，切片有三个属性，指针，长度，容量。 二者都可以用 make 进行初始化。

# **map** 

## map介绍

Go中Map是一个KV对集合。底层使用hash table，用链表来解决冲突 ，出现冲突时，不是每一个Key都申请一个结构通过链表串起来，而是以bmap为最小粒度挂载，一个bmap可以放8个kv。每个map的底层结构是hmap，是有若干个结构为bmap的bucket组成的数组。每个bucket底层都采用链表结构。bmap 就是我们常说的“桶”，桶里面会最多装 8 个 key，这些 key之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果是“一类”的，关于key的定位我们在map的查询和赋值中详细说明。在桶内，又会根据key计算出来的hash值的高8位来决定 key到底落入桶内的哪个位置（一个桶内最多有8个位置)。

## map的key的类型

`map[key]value`，其中key必须是可比较的，也就是可以通过`==`和`!=`进行比较，所以可以比较的类型才能作为key，其实就是等价问go语言中哪些类型是可以比较的：

什么可以比较：bool、array、numeric（浮点数、整数等）、pointer、string、interface、channel

什么不能比较：function、slice、map

golang中的map，的 key 可以是很多种类型，比如 bool, 数字，string, 指针, channel , 还有 只包含前面几个类型的 interface types, structs, arrays； map是可以进行嵌套的。

## map对象如何比较

使用**reflect.DeepEqual** 这个函数进行比较。使用 reflect.DeepEqual 有一点注意：由于使用了反射，所以有性能的损失。

## map的底层原理

1. map的实现原理
   1. go map是基于hash table（哈希表）来实现的，冲突的解决采用拉链法
2. map的底层结构
   1. hmap（哈希表）：每个hmap内含有多个bmap（buckets（桶）、oldbuckets（旧桶）、overflow（溢出桶））可以这样理解，每个哈希表都是由多个桶组成的

```
type hmap struct {
    count     int   	  	 //元素的个数
    flags     uint8  	 	 //状态标志
    B         uint8 	 	 //可以最多容纳 6.5 * 2 ^ B 个元素，6.5为装载因子
    noverflow uint16 	 	 //溢出的个数
    hash0     uint32   		 //哈希种子

    buckets    unsafe.Pointer //指向一个桶数组
    oldbuckets unsafe.Pointer //指向一个旧桶数组，用于扩容
    nevacuate  uintptr        //搬迁进度，小于nevacuate的已经搬迁
    overflow *[2]*[]*bmap     //指向溢出桶的指针
}

```

1. - buckets：一个指针，指向一个bmap数组、存储多个桶。
   - oldbuckets： 是一个指针，指向一个bmap数组，存储多个旧桶，用于扩容。
   - overflow：overflow是一个指针，指向一个元素个数为2的数组，数组的类型是一个指针，指向一个slice，slice的元素是桶(bmap)的地址，这些桶都是溢出桶。为什么有两个？因为Go map在哈希冲突过多时，会发生扩容操作。[0]表示当前使用的溢出桶集合，[1]是在发生扩容时，保存了旧的溢出桶集合。overflow存在的意义在于防止溢出桶被gc。
2. bmap（哈希桶）： bmap是一个隶属于hmap的结构体，一个桶（bmap）可以存储8个键值对。如果有第9个键值对被分配到该桶，那就需要再创建一个桶，通过overflow指针将两个桶连接起来。在hmap中，多个bmap桶通过overflow指针相连，组成一个链表。

```
type bmap struct {
    //元素hash值的高8位代表它在桶中的位置，如果tophash[0] < minTopHash，表示这个桶的搬迁状态
    tophash [bucketCnt]uint8
    //接下来是8个key、8个value，但是我们不能直接看到；为了优化对齐，go采用了key放在一起，value放在一起的存储方式，
    keys     [8]keytype   //key单独存储
	values   [8]valuetype //value单独存储
	pad      uintptr
	overflow uintptr	  //指向溢出桶的指针
}
```

## map 负载因子

负载因子用于衡量一个哈希表冲突情况，公式为：

```go
负载因子 = 键数量/bucket数量
```

例如，对于一个bucket数量为4，包含4个键值对的哈希表来说，这个哈希表的负载因子为1.哈希表需要将负载因子控制在合适的大小，超过其阀值需要进行rehash，也即键值对重新组织：

- 哈希因子过小，说明空间利用率低
- 哈希因子过大，说明冲突严重，存取效率低

每个哈希表的实现对负载因子容忍程度不同，比如Redis实现中负载因子大于1时就会触发rehash，而Go则在在负载因子达到6.5时才会触发rehash，因为Redis的每个bucket只能存1个键值对，而Go的bucket可能存8个键值对，所以Go可以容忍更高的负载因子。

## map哈希冲突解决

在Go语言中，普通的`map`类型在哈希冲突的情况下采用了开链法（链地址法）来解决。当不同的键经过哈希计算后映射到了同一个桶（bucket）时，就会产生哈希冲突。为了解决这些冲突，每个桶会维护一个链表，将哈希值相同的键值对链接在一起。以下是哈希冲突如何在Go中的普通`map`中解决的简要过程：

1. **哈希计算**：当插入或查找一个键值对时，首先会对键进行哈希计算，得到一个哈希值。
2. **映射到桶**：哈希值会被映射到一个特定的桶。Go中的`map`底层使用了一个哈希表，这个哈希表由多个桶组成。
3. **处理冲突**：如果两个不同的键的哈希值映射到了同一个桶，就会发生哈希冲突。此时，系统会将新的键值对添加到该桶对应的链表中。
4. **链表操作**：链表中的每个节点代表一个键值对，相同哈希值的键值对会链接在同一个桶的链表上。插入时会在链表头部插入节点，这使得查找和删除操作的时间复杂度相对较低。
5. **查找和删除**：对于查找操作，系统会先计算哈希值并找到对应的桶，然后遍历该桶的链表以找到目标键值对。对于删除操作，会在链表中找到目标键值对并将其从链表中移除

## map扩容机制

### 扩容条件

1. 负载因子大于6.5时，负载因子 = 键数量/bucket数量
2. overflow的数量达到2^min(B,15)时

### 增量扩容

新建一个bucket数组，新的bucket数组的长度是原来的两倍，然后旧bucket数组中的数据搬迁到新的bucket数组中。考虑到如果map存储了数以亿计的key-value，一次性搬迁将会造成比较大的延时，Go采用逐步搬迁策略，即每次访问map时都会触发一次搬迁，每次搬迁2个键值对。

### 等量扩容

所谓等量扩容，实际上并不是扩大容量，buckets数量不变，重新做一遍类似增量扩容的搬迁动作，把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。

## 实现线程安全的map

Map默认不是并发安全的，并发读写时程序会panic。map为什么不支持线程安全？和场景有关，官方认为大部分场景不需要多个协程进行并发访问，如果为小部分场景加锁实现并发访问，大部分场景将付出加锁代价（性能降低）。

- 加读写锁
- 分片加锁
- sync.Map

加读写锁、分片加锁，这两种方案都比较常用，后者的性能更好，因为它可以降低锁的粒度，提高访问此 map 对象的吞吐。前者并发性能虽然不如后者， 但是加锁的方式更加简单。sync.Map 是 Go 1.9 增加的一个线程安全的 map ，虽然是官方标准，但反而是不常用的，原因是 map 要解决的场景很难 描述，很多时候程序员在做抉择是否该用它，不过在一些特殊场景会使用 sync.Map，场景一：只会增长的缓存系统，一个 key 值写入一次而被读很多次； 场景二：多个 goroutine 为不相交的键读、写和重写键值对。对它的使用场景介绍，来自[官方文档 (opens new window)](https://golang.org/pkg/sync/#Map)，这里就不展开了。 加读写锁，扩展 map 来实现线程安全，支持并发读写。使用读写锁 RWMutex，是为了读写性能的考虑。 对 map 对象的操作，无非就是常见的增删改查和遍历。我们可以将查询和遍历看作读操作，增加、修改和 删除看作写操作。示例代码链接：https://github.com/guowei-gong/go-demo/blob/main/mutex/demo.go 。通过读写锁提供线程安全的 map，但是大量并发读写的情况下，锁的竞争会很激烈，导致性能降低。如何解决这个问题？ 尽量减少锁的粒度和锁的持有时间，减少锁的粒度，常用方法就是分片 Shard，将一把锁分成几把锁，每个锁控制一个分片。

## sync.map的实现

sync.map采用读写分离和用空间换时间的策略保证map的读写安全。

1. **散列桶和片段划分**：`sync.Map`的底层使用了一个散列桶数组来存储键值对。这个数组被划分成多个小的片段，每个片段有自己的锁，这样不同的片段可以独立地进行操作，从而减少了竞争。
2. **读写分离**：为了允许高并发读取，`sync.Map`实现了一种读写分离的机制。在读取时，不需要锁定，多个goroutine可以并发读取。写操作涉及到写入数据，会获取特定散列桶的写锁。
3. **散列算法和冲突解决**：`sync.Map`使用散列算法将键映射到散列桶。每个散列桶中都可能包含多个键值对，因此可能会出现散列冲突。冲突的解决方式通常是通过链表来存储具有相同散列的键值对。
4. **版本控制**：`sync.Map`引入了版本控制的概念。每个散列桶中都包含了一个版本号，用于跟踪对散列桶的修改。这使得在读取时可以检测到同时进行的写入，从而确保读取的数据的一致性。
5. **内存管理和垃圾回收**：`sync.Map`还包含了一些内存管理机制，以避免不再使用的内存积累。当某个散列桶不再被使用时，相应的内存可能会被释放。

基本结构：

```
type Map struct {
    mu Mutex
    read atomic.Value 	 //包含对并发访问安全的map内容的部分(无论是否持有mu)
    dirty map[ant]*entry //包含map内容中需要保存mu的部分
    misses int 			//计算自从上次读取map更新后，需要锁定mu来确定key是否存在的加载次数
}
```

![image-20230813151541034](D:\typora\Golang_Engineer\typora-user-images\image-20230813151541034.png)

**read：**read 使用 `map[any]*entry` 存储数据，本身支持无锁的并发读read 可以在无锁的状态下支持 CAS 更新，但如果更新的值是之前**已经删除过的** entry 则需要加锁操作由于 read 只负责读取，dirty 负责写入，因此使用 `amended` 来标记 dirty 中是否包含 read 没有的字段

**dirty：**dirty 本身就是一个原生 map，需要加锁保证并发写入

**entry：**read 和 dirty 都是用到 entry 结构entry 内部只有一个 unsafe.Pointer 指针 p 指向 entry 实际存储的值指针 p 有三种状态

- p == nil

  在此状态下对应： entry 已经被删除 或 map.dirty == nil 或 map.dirty 中有 key 指向 e ==此处不明==

- p == expunged

  在此状态下对应：entry 已经被删除 或 map.dirty != nil 同时该 entry 无法在 dirty 中找到

- 其他情况

  entry 都是有效状态并被记录在 read 中，如果 dirty 不为空则也可以在 dirty 中找到

### 场景

1. 只会增长的缓存系统，一个key只写一次而被读很多次
2. 多个goroutine为不相交的键集读、写和重写键值对

## map和sync.map的区别

1. 线程安全性：`map` 是非线程安全的，多个 goroutine 并发地读写 `map` 可能会导致数据竞争和不确定的结果。而 `sync.Map` 是线程安全的，可以在多个 goroutine 并发地读写 `sync.Map`，而不需要额外的同步操作。
2. 扩容机制：`map` 的扩容是在插入新元素时自动进行的，按需增加内部哈希表的大小。而 `sync.Map` 不会自动扩容，它始终使用固定大小的内部哈希表。
3. 功能和方法：`map` 提供了常见的读取、插入、更新和删除等操作，如 `m[key]`、`m[key] = value`、`delete(m, key)` 等。而 `sync.Map` 提供了一组特定的方法，如 `Load`、`Store`、`Delete` 和 `Range`，用于读取、存储、删除和遍历键值对。
4. 性能：由于 `sync.Map` 是线程安全的，它需要进行额外的同步操作，因此在并发性能方面可能会比普通的 `map` 稍慢。而普通的 `map` 在单个 goroutine 下的读取和写入操作性能较高

## map查找过程

查找过程如下：

1. 根据key值算出哈希值
2. 取哈希值低位与hmap.B取模确定bucket位置
3. 取哈希值高位在tophash数组中查询
4. 如果tophash[i]中存储值和当前key的哈希值相等，则去找到该bucket中的key值进行比较
5. 当前bucket没有找到，则继续从下个overflow的bucket中查找。
6. 如果当前处于搬迁过程，则优先从oldbuckets查找

注：如果查找不到，也不会返回空值，而是返回相应类型的0值。

## map插入过程

新元素插入过程如下：

1. 根据key值算出哈希值
2. 取哈希值低位与hmap.B取模确定bucket位置
3. 查找该key是否已经存在，如果存在则直接更新值
4. 如果没找到将key，将key插入

## map没申请空间，取值，会发生什么情况

在map查询操作中，最多可以给两个变量赋值，第一个为值，第二个为bool类型的变量，用于指示是否存在指定的键，如果键不存在，那么第一个值为相应类型的零值。如果只指定一个变量，那么该变量仅表示改键对应的值，如果键不存在，那么该值同样为相应类型的零值。

## set的原理，Java 的HashMap和 go 的map底层原理

**1. Set原理:** Set特性: 1. 不包含重复key. 2.无序. 如何去重: 通过查看源码add(E e)方法，底层实现有一个map，map是HashMap,Hash类型是散列，所以是无序的. 如果key值相同，将会覆盖，这就是set为什么能去重的原因(key相同会覆盖). **注意:** 如果new出两个对象add到set中,因为两个对象的地址不相同,所以map在计算key的hash值时，将它当成了两个不同的元素。这时要重写equals和hashcode两个方法。 这样才能保证set集合的元素不重复.

**2. Java HashMap:**

线程不安全 安全的map(CurrentHashMap) HashMap由数组+链表组成,数组是HashMap的主体, 链表则是为了解决哈希冲突而存在的,如果定位到的数组位置不含链表（当前entry的next指向null）,那么查找，添加等操作很快，仅需一次寻址即可； 如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增； 对于查找操作来讲，仍需遍历链表，然后通过key对象的equals方法逐一比对查找。 所以，性能考虑，HashMap中的链表出现越少，性能才会越好。 假如一个数组槽位上链上数据过多（即链表过长的情况）导致性能下降该怎么办？ JDK1.8在JDK1.7的基础上针对增加了红黑树来进行优化。 即当链表超过8时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。

**3. go map:**

线程不安全 安全的map(sync.map) 特性: 1. 无序. 2. 长度不固定. 3. 引用类型. 底层实现: 1.hmap 2.bmap(bucket) hmap中含有n个bmap，是一个数组. 每个bucket又以链表的形式向下连接新的bucket. bucket关注三个字段: 1. 高位哈希值 2. 存储key和value的数组 3. 指向扩容bucket的指针 高位哈希值: 用于寻找bucket中的哪个key. 低位哈希值: 用于寻找当前key属于hmap中的哪个bucket. map的扩容: 当map中的元素增长的时候，Go语言会将bucket数组的数量扩充一倍，产生一个新的bucket数组，并将旧数组的数据迁移至新数组。 加载因子 判断扩充的条件，就是哈希表中的加载因子(即loadFactor)。 加载因子是一个阈值，一般表示为：散列包含的元素数 除以 位置总数。是一种“产生冲突机会”和“空间使用”的平衡与折中：加载因子越小，说明空间空置率高，空间使用率小，但是加载因子越大，说明空间利用率上去了，但是“产生冲突机会”高了。 每种哈希表的都会有一个加载因子，数值超过加载因子就会为哈希表扩容。 Golang的map的加载因子的公式是：map长度 / 2^B(这是代表bmap数组的长度，B是取的低位的位数)阈值是6.5。其中B可以理解为已扩容的次数。 当Go的map长度增长到大于加载因子所需的map长度时，Go语言就会将产生一个新的bucket数组，然后把旧的bucket数组移到一个属性字段oldbucket中。注意：并不是立刻把旧的数组中的元素转义到新的bucket当中，而是，只有当访问到具体的某个bucket的时候，会把bucket中的数据转移到新的bucket中。 map删除: 并不会直接删除旧的bucket，而是把原来的引用去掉，利用GC清除内存。

# **channel**

## channel介绍

channel是Golang在语言层面提供的goroutine间的通信方式，channel主要用于进程内各goroutine间的通信。channel分为无缓冲channel和有缓冲channel。

Channel 在 gouroutine 间架起了一条管道，在管道里传输数据，实现 gouroutine 间的通信；在并发编程中它线程安全的，所以用起来非常方便；channel 还提供“先进先出”的特性；它还能影响 goroutine 的阻塞和唤醒。

## channel底层实现

### 背景

- Go语言提供了一种不同的并发模型--通信顺序进程(communicating sequential processes,CSP)。
- 设计模式：通过通信的方式共享内存
- channel收发操作遵循先进先出(FIFO)的设计

### 底层结构

```go
type hchan struct {
    qcount   uint           // 当前队列中剩余元素个数
    dataqsiz uint           // 环形队列长度，即可以存放的元素个数
    buf      unsafe.Pointer // 环形队列指针
    elemsize uint16         // 每个元素的大小
    closed   uint32            // 标识关闭状态
    elemtype *_type         // 元素类型
    sendx    uint           // 队列下标，指示元素写入时存放到队列中的位置
    recvx    uint           // 队列下标，指示元素从队列的该位置读出
    recvq    waitq          // 等待读消息的goroutine队列
    sendq    waitq          // 等待写消息的goroutine队列
    lock mutex              // 互斥锁，chan不允许并发读写
}
```

从数据结构可以看出channel由队列、类型信息、goroutine等待队列组成，channel内部数据结构主要包含：

- 环形队列
- 等待队列(读队列和写队列)
- mutex

### 缓冲区—环形队列

chan内部实现了一个环形队列作为其缓冲区，队列的长度是创建chan时指定的。

![image-20230813164252270](D:\typora\Golang_Engineer\typora-user-images\image-20230813164252270.png)

- dataqsiz指示了队列长度为6，即可缓存6个元素；
- buf指向队列的内存，队列中还剩余两个元素；
- qcount表示队列中还有两个元素；
- sendx指示后续写入的数据存储的位置，取值[0, 6)；
- recvx指示从该位置读取数据, 取值[0, 6)；

### 等待队列

从channel读数据，如果channel缓冲区为空或者没有缓冲区，当前goroutine会被阻塞。
向channel写数据，如果channel缓冲区已满或者没有缓冲区，当前goroutine会被阻塞。

被阻塞的goroutine将会挂在channel的等待队列中：

- 因读阻塞的goroutine会被向channel写入数据的goroutine唤醒；
- 因写阻塞的goroutine会被从channel读数据的goroutine唤醒；

## channel 读写

### 写数据

向一个channel中写数据简单过程如下：

1. 如果等待接收队列recvq不为空，说明缓冲区中没有数据或者没有缓冲区，此时直接从recvq取出G,并把数据写入，最后把该G唤醒，结束发送过程；
2. 如果缓冲区中有空余位置，将数据写入缓冲区，结束发送过程；
3. 如果缓冲区中没有空余位置，将待发送数据写入G，将当前G加入sendq，进入睡眠，等待被读goroutine唤醒；

### 读数据

1. 如果等待发送队列sendq不为空，且没有缓冲区，直接从sendq中取出G，把G中数据读出，最后把G唤醒，结束读取过程；
2. 如果等待发送队列sendq不为空，此时说明缓冲区已满，从缓冲区中首部读出数据，把G中数据写入缓冲区尾部，把G唤醒，结束读取过程；
3. 如果缓冲区中有数据，则从缓冲区取出数据，结束读取过程；
4. 将当前goroutine加入recvq，进入睡眠，等待被写goroutine唤醒；

## 出现panic的场景

关闭channel时会把recvq中的G全部唤醒，本该写入G的数据位置为nil。把sendq中的G全部唤醒，但这些G会panic。

除此之外，panic出现的常见场景还有：

1. 关闭值为nil的channel
2. 关闭已经被关闭的channel
3. 向已经关闭的channel写数据

## 出现阻塞的场景

1. 无缓冲区读写数据会阻塞
2. 缓冲区已满，写入会阻塞；缓冲区为空，读取数据会阻塞
3. 值为nil读写数据会阻塞

## channel和锁对比

并发问题可以用channel解决也可以用Mutex解决，但是它们的擅长解决的问题有一些不同。channel关注的是并发问题的数据流动，适用于数据在多个协程中流动的场景。而mutex关注的是是数据不动，某段时间只给一个协程访问数据的权限，适用于数据位置固定的场景。

## channel应用场景

channel适用于数据在多个协程中流动的场景，有很多实际应用：

1. 定时任务：超时处理
2. 解耦生产者和消费者，可以将生产者和消费者解耦出来，生产者只需要往channel发送数据，而消费者只管从channel中获取数据。
3. 控制并发数：以爬虫为例，比如需要爬取1w条数据，需要并发爬取以提高效率，但并发量又不过过大，可以通过channel来控制并发规模，比如同时支持5个并发任务

## 有无缓冲在使用上的区别

无缓冲：发送和接收需要同步。 有缓冲：不要求发送和接收同步，缓冲满时发送阻塞。 因此 channel 无缓冲时，发送阻塞直到数据被接收，接收阻塞直到读到数据；channel有缓冲时，当缓冲满时发送阻塞，当缓冲空时接收阻塞。

## channel是否线程安全

- channel为什么设计成线程安全? 不同协程通过channel进行通信，本身的使用场景就是多线程，为了保证数据的一致性，必须实现线程安全。
- channel如何实现线程安全的? channel的底层实现中， hchan结构体中采用Mutex锁来保证数据读写安全。在对循环数组buf中的数据进行入队和出队操作时，必须先获取互斥锁，才能操作channel数据。

## 用channel实现分布式锁

分布式锁定义-控制分布式系统有序的去对共享资源进行操作，通过互斥来保持一致性。 通过数据库，redis，zookeeper都可以实现分布式锁。其中，最常见的是用redis的setnx实现。

通过channel作为媒介，利用struct{}{}作为信号，判断struct{}{}是否存在进行加锁、解锁操作。

## go channel实现归并排序

```go
func Merge(ch1 <-chan int, ch2 <-chan int) <-chan int {
 
    out := make(chan int)
 
    go func() {
        // 等上游的数据 （这里有阻塞，和常规的阻塞队列并无不同）
        v1, ok1 := <-ch1
        v2, ok2 := <-ch2
        
        // 取数据
        for ok1 || ok2 {
            if !ok2 || (ok1 && v1 <= v2) {
                // 取到最小值, 就推到 out 中
                out <- v1
                v1, ok1 = <-ch1
            } else {
                out <- v2
                v2, ok2 = <-ch2
            }
        }
        // 显式关闭
        close(out)
    }()
 
    // 开完goroutine后, 主线程继续执行, 不会阻塞
    return out
```

## 判断channel已关闭

**方式1：通过读chennel实现**

用 select 和 <-ch 来结合判断，ok的结果和含义： true：读到数据，并且[通道 (opens new window)](https://so.csdn.net/so/search?q=通道&spm=1001.2101.3001.7020)没有关闭。 false：通道关闭，无数据读到。需要注意： 1.case 的代码必须是 _, ok:= <- ch 的形式，如果仅仅是 <- ch 来判断，是错的逻辑，因为主要通过 ok的值来判断； 2.select 必须要有 default 分支，否则会阻塞函数，我们要保证一定能正常返回；

**方式2：通过context**

通过一个 ctx 变量来指明 close 事件，而不是直接去判断 channel 的一个状态. 当ctx.Done()中有值时，则判断channel已经退出。注意: select 的 case 一定要先判断 ctx.Done() 事件，否则很有可能先执行了 chan 的操作从而导致 panic 问题；

## chan和共享内存的优劣势

Go的设计思想就是, 不要通过共享内存来通信，而是通过通信来共享内存，前者就是传统的加锁，后者就是Channel。 共享内存是在操作内存的同时，通过互斥锁、CAS等保证并发安全，而channel虽然底层维护了一个互斥锁，来保证线程安全，但其可以理解为先进先出的队列，通过管道进行通信。 共享内存优势是资源利用率高、系统吞吐量大,劣势是平均周转时间长、无交互能力。 channel优势是降低了并发中的耦合，劣势是会出现死锁。

## 使用chan不占内存空间实现传递信息

```
// 空结构体的宽度是0，占用了0字节的内存空间。
// 所以空结构体组成的组合数据类型也不会占用内存空间。
channel := make(chan struct{})
go func() {
    // do something
    channel <- struct{}{}
}()
fmt.Println(<-channel)

```

## go中的syncLock和channel的性能区别

hannel的底层也是用了syns.Mutex,算是对锁的封装，性能应该是有损耗的。根据压测结果来说Mutex 比 channel的性能快了两倍左右

## 同一个协程里面，对无缓冲channel同时发送和接收数据有什么问题

同一个协程里，不能对无缓冲channel同时发送和接收数据，如果这么做会直接报错死锁。对于一个无缓冲的channel而言，只有不同的协程之间一方发送数据一方接受数据才不会阻塞。channel无缓冲时，发送阻塞直到数据被接收，接收阻塞直到读到数据。

# MySQL索引

## B+树

## MySQLB+树的实现

MySQL中使用B+树来实现索引结构，提高查询效率和数据的访问速度。下面是MySQL中B+树的基本实现原理：

1. B+树结构：MySQL的B+树是一种平衡多路搜索树，具有以下特点：

   - 所有数据都存储在叶子节点上，且叶子节点之间通过指针连接形成有序链表。
   - 非叶子节点（内部节点）仅用于索引，存储索引值以及指向子节点的指针。
   - 叶子节点包含实际的数据值和对应的主键。

1. B+树索引的创建：在MySQL中，通过CREATE INDEX语句或ALTER TABLE语句创建索引时，会自动创建对应的B+树索引结构。索引的创建过程包括以下步骤：

   - 读取表中的数据，并按照索引列的值构建B+树结构。
   - 分裂节点：如果插入数据导致节点超过限定的最大键值数，节点会被分裂为两个节点，并调整父节点的指针。
   - 重复上述过程，直到所有数据都插入到B+树中。

1. B+树索引的维护：在插入、更新或删除数据时，MySQL会相应地更新B+树索引结构，以保持数据的一致性和索引的有效性。维护过程包括以下操作：

   - 插入数据：根据插入的值找到对应的叶子节点，并将数据插入到合适的位置。如果叶子节点已满，会触发节点的分裂操作。
   - 更新数据：首先通过索引查找到需要更新的数据所在的叶子节点，然后更新数据的值。
   - 删除数据：类似于插入操作，找到需要删除的数据所在的叶子节点，并将其删除。如果删除后的叶子节点元素数量低于阈值，会触发节点的合并操作。

通过B+树索引，MySQL可以快速定位到满足查询条件的数据所在的叶子节点，避免全表扫描，提高查询效率。同时，B+树结构的有序性也有利于范围查询和排序操作的执行。

需要注意的是，MySQL的B+树索引是一种典型的索引结构，具体的实现细节可能会因版本和配置而有所差异。此外，MySQL还支持其他类型的索引，如哈希索引、全文索引等，根据具体的使用场景和需求，可以选择适合的索引类型来优化查询性能。

## B+树为什么这么快

B+树之所以在数据库中常用且被认为是高效的索引结构，是因为它具有以下特点，从而提供了高效的查询和数据访问速度：

1. 顺序访问：B+树的叶子节点之间通过指针连接形成有序链表，这使得范围查询操作非常高效。相邻的数据项在磁盘上通常是连续存储的，这利用了磁盘预取机制，可以一次性读取多个数据项，减少了磁盘IO的次数，提高了访问速度。

1. 层级结构：B+树是一种平衡多路搜索树，具有多个层级。每个层级上的节点数相对较少，使得索引的高度较低。这样，对于具有大量数据的数据库表，B+树的查询时间复杂度是O(log n)，其中n是数据项的数量。较低的查询复杂度意味着更快的查询速度。

1. 节点利用率高：B+树的内部节点仅用于存储索引值和指向子节点的指针，而实际的数据存储在叶子节点上。这样，每个节点可以容纳更多的索引项，提高了节点的利用率。高节点利用率意味着索引结构在内存中占用的空间较小，可以减少磁盘IO的次数，进一步提高查询速度。

1. 分裂和合并操作：B+树在插入和删除数据时，通过节点的分裂和合并操作来保持树的平衡性。分裂操作将一个节点分成两个节点，并调整父节点的指针，使得树保持平衡。合并操作将两个相邻的节点合并为一个节点，同样调整父节点的指针。这样的平衡调整操作可以确保B+树的高度较低，提供了快速的查询性能。

总结来说，B+树之所以快速，是因为它利用了顺序访问、多级索引、高节点利用率以及平衡调整等特点。这些特点使得B+树在大型数据库中能够高效地支持范围查询、排序操作和快速数据定位，提供了优秀的查询性能和数据访问速度。

## B+树、B树、哈希的区别

B+树索引、B树索引和哈希索引是数据库中常见的索引结构，它们在实现原理和适用场景上有一些区别：

1. B+树索引：

   - 结构：B+树是一种平衡多路搜索树，具有多个层级。所有数据存储在叶子节点上，叶子节点之间通过指针连接形成有序链表。非叶子节点仅用于索引，存储索引值和子节点指针。
   - 特点：
     - 有序性：B+树的叶子节点形成有序链表，适合范围查询和排序操作。
     - 高度较低：B+树具有多级索引结构，查询时间复杂度为O(log n)。
     - 支持顺序访问：相邻数据项在磁盘上通常是连续存储的，利用了磁盘预取机制，提高了访问速度。
   - 适用场景：适用于范围查询、排序操作和大型数据库。

1. B树索引：

   - 结构：B树也是一种平衡搜索树，与B+树类似，但B树的叶子节点和非叶子节点都存储数据。
   - 特点：
     - 平衡性：B树通过节点的分裂和合并操作保持树的平衡。
     - 适用于随机访问：B树的数据存储在各级节点中，适合随机访问的场景。
   - 适用场景：适用于较小的数据库，以及随机访问较多的情况。

1. 哈希索引：

   - 结构：哈希索引使用哈希函数将索引值映射到索引桶，每个桶存储具有相同哈希值的索引项。
   - 特点：
     - 快速哈希查找：哈希索引通过哈希函数直接计算索引项的存储位置，具有非常快速的查找速度。
     - 不支持范围查询和排序：哈希索引不适合范围查询和排序操作，因为数据在存储中的物理顺序是任意的。
   - 适用场景：适用于等值查询频繁且不需要范围查询和排序的场景，例如主键或唯一索引。

需要根据具体的应用需求和数据访问模式选择合适的索引结构。在实际数据库中，通常会根据表的特点和查询需求使用多种索引类型来优化查询性能。

## 索引是什么? 索引优缺点? 

索引是一种数据结构，用于快速查找和检索数据。它们在很多场景中都非常有用，比如数据库查询、文本搜索引擎和文件系统。当我们谈论索引时，通常是指数据库索引，它们作用于数据库表，通过对表中的一列或多列进行排序和组织，从而提高查询速度。

**优点：**

1. 提高查询速度：索引的主要优点是能显著提高数据查找速度。通过使用索引，数据库可以避免全表扫描，从而更快地定位到所需的数据行。

2. 加速表连接：在多表连接查询中，使用索引可以显著提高连接速度。数据库可以利用索引在两个表之间更快地找到匹配的行。

3. 提高排序和分组速度：索引可以帮助数据库在排序和分组数据时更高效地工作。如果已经存在一个排序索引，那么数据库在进行排序操作时可以直接使用索引，而不需要额外的排序步骤。

**缺点：**

1. 占用存储空间：索引需要占用额外的存储空间，因为它们本身也是数据结构。对于大型数据库，索引可能占用相当大的空间。

2. 插入、更新和删除操作变慢：当对表中的数据进行插入、更新或删除操作时，数据库需要同时更新相关索引。这会导致这些操作的速度变慢，因为每次执行这些操作时，都需要维护索引结构。

3. 索引管理和维护开销：创建和维护索引需要额外的计算资源和时间。在数据库中添加或修改索引时，需要进行索引重建，这会消耗大量的计算资源。此外，索引的选择和调优需要专业知识，以确保数据库性能得到优化。

总之，索引是一种在查询速度和数据修改速度之间进行权衡的技术。在选择是否使用索引时，需要根据具体应用场景和需求进行评估。在查询密集型应用中，索引往往非常有益；而在数据更新频繁的场景中，索引可能导致性能下降。因此，在创建和使用索引时，需要充分考虑它们的优缺点。

## MySQL索引类型*

![image-20230730204209557](D:\typora\Golang_Engineer\typora-user-images\image-20230730204209557.png)

## 索引底层实现? 为什么使用B+树, 而不是B树, BST, AVL, 红黑树等等?

索引的底层实现通常使用树型数据结构。这是因为树型数据结构在搜索、插入、删除等操作中具有较高的效率。主流的数据库系统（如 MySQL、Oracle、SQL Server 等）主要使用 B-Tree（B 树）或其变种 B+树，作为索引的底层数据结构。下面我们来探讨为什么使用 B+树，而不是其他树型数据结构（如 B 树、BST、AVL、红黑树等）。

**B+树相较于B树的优点：**

1. B+树的所有叶子节点都存储了索引信息，并且通过指针相互连接，便于进行范围查找。而 B 树只有部分节点存储索引信息，范围查找效率较低。

2. B+树的内部节点只存储键值，不存储实际数据，这使得每个内部节点可以存储更多的键值，从而降低了树的高度。相比之下，B 树的每个节点都存储了实际数据，占用更多空间，树的高度可能更高。

3. B+树的查询性能更稳定，因为所有查询都需要遍历到叶子节点。而在 B 树中，查询性能取决于数据所在的节点层级，可能导致性能波动。

4. 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；

5. 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；
6. 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。
7. 非叶子节点中有多少个子节点，就有多少个索引；

**B+树相较于BST、AVL、红黑树等平衡二叉查找树的优点：**

1. B+树是多路平衡查找树，每个节点可以有多个孩子，而平衡二叉查找树每个节点只有两个孩子。多路查找树可以减少树的高度，从而降低磁盘 I/O 操作次数，提高查询速度。

2. B+树具有更好的磁盘空间利用率。在数据库系统中，读取磁盘数据的最小单位是页（Page），B+树的节点大小通常设定为页的大小。这样，每次磁盘 I/O 操作可以将一个完整的 B+树节点加载到内存中。而 BST、AVL、红黑树等平衡二叉查找树的节点大小通常远小于页的大小，导致每次磁盘 I/O 操作无法充分利用磁盘空间，降低了空间利用率。

3. 平衡二叉查找树在插入和删除操作时，需要进行旋转操作来维护平衡。在数据库系统中，旋转操作可能导致大量的磁盘 I/O 操作，降低性能。而 B+树在插入和删除操作时，只需要分裂和合并节点，不需要进行旋转操作，性能更高。

综上所述，B+树作为数据库索引的底层实现，相较于其他树型数据结构具有较高的查询效率、更好的磁盘空间利用率和更稳定的性能。这些优点使得 B+树成为数据库领域中主流的索引数据结构。

## 什么是聚簇索引和非聚簇索引?

聚簇索引（Clustered Index）和非聚簇索引（Non-Clustered Index）是两种不同类型的数据库索引，它们在数据存储和查询性能方面有一些区别。以下是关于聚簇索引和非聚簇索引的详细解释：

**聚簇索引（Clustered Index）：**

1. 聚簇索引并不是一种独立的索引类型，而是指数据行与索引行在存储上的排列方式。在聚簇索引中，表中的数据行按照索引键的顺序存储在磁盘上。换句话说，聚簇索引定义了表中数据的物理存储顺序。

2. 由于聚簇索引决定了数据的物理顺序，因此每个表只能有一个聚簇索引。在具有聚簇索引的表中，数据行的查找非常快，因为索引键值可以直接指向数据行的存储位置。

3. 一些数据库管理系统（如 SQL Server 和 MySQL 的 InnoDB 存储引擎）会自动创建聚簇索引。通常情况下，聚簇索引是基于表的主键创建的。

**非聚簇索引（Non-Clustered Index）：**

1. 非聚簇索引是一种独立于表数据的索引结构。非聚簇索引存储了索引键值和指向数据行的指针（或数据行的聚簇索引键值）。非聚簇索引与表数据的存储顺序无关，因此可以为表创建多个非聚簇索引。

2. 在非聚簇索引中，索引键和数据行分开存储，这意味着查询时需要额外的 I/O 操作来获取数据行。首先，数据库系统需要查找非聚簇索引以找到数据行的指针（或聚簇索引键值），然后再根据指针（或聚簇索引键值）查找数据行。这个过程被称为“回表”（Key Lookup 或 Bookmark Lookup）。

3. 非聚簇索引适用于过滤、排序和聚合等操作，特别是当查询只涉及索引键值时（即覆盖索引查询），非聚簇索引的性能非常高。

总之，聚簇索引和非聚簇索引在数据存储和查询性能方面有一些区别。聚簇索引决定了表中数据的物理存储顺序，查询速度快，但每个表只能有一个。非聚簇索引独立于表数据，可以为表创建多个，适用于过滤、排序和聚合等操作。在实际应用中，根据查询需求和性能要求选择合适的索引类型，以优化数据库的整体性能。

**区别**

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。

## 非聚簇索引一定会回表吗?

​	非聚簇索引不一定会回表。在某些情况下，非聚簇索引可以避免回表操作，从而提高查询性能。这种情况通常发生在**覆盖索引**（Covering Index）查询中。覆盖索引是指查询所需的所有列都包含在非聚簇索引中的情况。也就是说，非聚簇索引包含了查询所需的全部数据，因此无需回表到数据行以获取额外的信息。在这种情况下，数据库系统可以直接从非聚簇索引中获取查询结果，从而避免了回表操作。

​	非聚簇索引不一定会回表。当查询只涉及覆盖索引中的列时，可以避免回表操作，从而提高查询性能。为了充分利用覆盖索引优势，可以根据查询需求设计合适的非聚簇索引，使其包含查询所需的所有列。

## 什么是联合索引?为什么需要注意联合索引中的字段顺序?

联合索引（Compound Index，也称为复合索引或多列索引）是一种数据库索引，它包含两个或多个列的值。使用联合索引可以根据多个列的值快速定位到数据行。联合索引的主要目的是优化多列过滤条件的查询性能。

在联合索引中，字段顺序非常重要，原因如下：

1. **查询性能：** 联合索引的查询性能取决于查询条件中涉及的列以及它们在索引中的顺序。当查询条件完全匹配索引的前导列（最左边的列）时，查询性能最佳。如果查询条件仅涉及索引的非前导列，则联合索引可能无法发挥其性能优势。因此，在创建联合索引时，应该将查询条件中最常用的列放在前面，以提高查询性能。

2. **索引选择性：** 索引选择性（Index Selectivity）是指索引中不重复值的比例。具有较高选择性的索引通常具有更好的查询性能，因为它们可以更快地过滤出不符合条件的行。在创建联合索引时，应将具有较高选择性的列放在前面，以提高索引的选择性。

3. **排序和分组操作：** 联合索引可以提高排序和分组操作的性能，但这取决于排序或分组列的顺序与索引中的字段顺序相匹配。在创建联合索引时，应考虑将通常用于排序或分组的列放在索引中的适当位置。

4. **覆盖索引：** 如前所述，覆盖索引（Covering Index）是指查询所需的所有列都包含在索引中，从而避免回表操作。在联合索引中，字段顺序也会影响覆盖索引的性能。因此，在设计联合索引时，应确保查询所需的所有列都包含在索引中，并注意列的顺序。

总之，联合索引中的字段顺序对查询性能、索引选择性、排序和分组操作以及覆盖索引等方面具有重要意义。在创建联合索引时，应根据查询需求和性能要求合理安排字段顺序，以充分发挥联合索引的优势。

## 什么是最左前缀原则?

最左前缀原则（Leftmost Prefix Principle）是指在使用联合索引（Compound Index）时，查询条件必须使用索引的最左边的一列或连续多列，以便数据库引擎能够充分利用索引来优化查询性能。最左前缀原则是数据库查询优化的一个重要原则，它涉及到联合索引的列顺序和查询条件的匹配。

## 什么是前缀索引?

前缀索引（Prefix Index）是一种对数据库表中字符串类型列的部分内容进行索引的方法。在某些情况下，为了节省存储空间并提高查询性能，我们可能不需要对整个字符串进行索引，而只需要对字符串的前缀部分进行索引。前缀索引可以减少索引的大小，从而提高查询速度和降低维护成本。

需要注意的是，前缀索引也有一些限制和缺点：

1. **兼容性问题：** 并非所有数据库系统都支持前缀索引。例如，MySQL 支持前缀索引，而 PostgreSQL 和 SQL Server 则不支持。
2. **查询限制：** 使用前缀索引时，查询条件中的 LIKE 运算符可能无法充分利用索引。例如，当查询条件中使用了后缀通配符（如 `url LIKE 'http://example.com/%'`）时，前缀索引可以发挥作用；但如果查询条件中使用了前缀通配符（如 `url LIKE '%/example.html'`），前缀索引将无法提高查询性能。
3. **准确性问题：** 前缀索引可能导致查询结果不准确，因为只有部分字符串内容被索引。因此，在创建前缀索引时，需要确保所选的前缀长度足够区分不同的字符串值。

总之，前缀索引是一种针对字符串类型列的部分内容进行索引的方法，可以节省存储空间并提高查询性能。但在使用前缀索引时，需要注意兼容性问题、查询限制以及准确性问题。

## 什么是索引下推?

1. 索引下推（Index Condition Pushdown，简称 ICP）是一种数据库查询优化技术，它允许数据库管理系统在索引扫描过程中对查询条件进行过滤。通过将过滤操作提前到索引扫描阶段，可以减少从磁盘读取数据的次数，从而提高查询性能。
2. 在没有应用索引下推优化的情况下，数据库系统通常会先执行索引扫描，然后将符合索引条件的记录从磁盘加载到内存中，最后再过滤掉不符合其他查询条件的记录。这样做的缺点是，如果有很多记录符合索引条件，但不符合其他查询条件，那么将会产生大量无效的磁盘 I/O。
3. 索引下推的优势在于，它将过滤操作提前到索引扫描阶段，这样只有符合所有查询条件的记录才会被加载到内存中。这有助于减少无效的磁盘 I/O，提高查询效率。
4. 需要注意的是，索引下推优化并非适用于所有情况，它取决于数据库管理系统的具体实现以及查询条件的复杂程度。在实际应用中，数据库查询优化器通常会自动决定是否启用索引下推优化。

## 如何查看MySQL语句是否使用到索引?

在MySQL中，你可以使用`EXPLAIN`命令来查看查询语句的执行计划，从而判断是否使用了索引。`EXPLAIN`命令会返回关于查询语句如何使用索引、表连接顺序等详细信息。要查看一个查询语句是否使用了索引，你可以在查询语句前加上`EXPLAIN`关键字，然后执行该语句。

## 为什么建议使用自增主键作为索引?

使用自增主键作为索引有以下几个原因：

1. **唯一性**：自增主键保证了每个记录的主键ID是唯一的。这对于数据库系统来说很重要，因为唯一性有助于确保数据的完整性，避免因重复数据导致的问题。唯一的主键也意味着更高效的索引，因为数据库可以直接通过主键查找到唯一的记录，而无需检查其他列。

2. **插入性能**：自增主键在插入新记录时，会为每个新记录分配一个比前一个记录更大的ID。由于自增主键是递增的，这意味着新插入的数据会被添加到索引的末尾。这对于插入性能有很大的优势，因为数据库不需要在中间位置插入记录并重新调整索引结构。相比之下，如果使用非自增主键作为索引，插入新记录可能会导致索引结构频繁调整，从而降低插入性能。

3. **避免热点问题**：自增主键在插入新数据时，由于数据是逐步增长的，因此可以避免热点问题。热点问题是指在某个特定区域集中访问数据的情况，这可能导致数据库性能下降。使用自增主键作为索引，可以将数据分散在整个索引结构中，从而避免热点问题。

4. **简化查询**：使用自增主键作为索引，可以简化查询语句。因为主键ID是唯一的，所以你可以直接根据主键ID查询记录，而无需在查询条件中包含其他列。这有助于提高查询性能，因为数据库只需要检查一个索引列。

需要注意的是，虽然使用自增主键作为索引有很多优势，但这并不意味着它适用于所有情况。在某些特定场景下，使用其他类型的主键或复合索引可能更合适。因此，在设计数据库结构时，需要根据实际需求和性能考虑选择合适的索引策略。

## **建立索引的原则** 

建立索引时，需要遵循一定的原则，以确保索引能够提高查询性能并在维护和存储方面保持高效。以下是建立索引的一些建议原则：

1. **选择性高的列**：索引具有较高选择性的列，即具有大量不同值的列。高选择性的列可以更有效地过滤记录，从而提高查询性能。相反，具有较低选择性的列（如性别、布尔值等）可能不适合建立索引，因为它们不能有效地过滤记录。

2. **频繁用于查询条件的列**：为经常用于查询条件（如WHERE子句、JOIN操作等）的列创建索引。这可以提高这些查询的性能。同时，也可以考虑创建复合索引，将多个频繁用于查询条件的列组合在一起。

3. **用于排序和分组的列**：为经常用于排序（ORDER BY子句）和分组（GROUP BY子句）的列创建索引。这可以加速排序和分组操作。

4. **避免过多的索引**：每个索引都需要额外的存储空间和维护成本。过多的索引会增加数据库的存储需求，并可能降低写操作（如插入、更新和删除）的性能。因此，在创建索引时要权衡利弊，避免为不常用的查询创建不必要的索引。

5. **谨慎使用全文索引**：全文索引（Full-Text Index）适用于针对大量文本数据的搜索场景。虽然全文索引可以提高文本搜索性能，但它们需要额外的存储空间和维护成本。因此，在创建全文索引时要谨慎评估实际需求。

6. **使用合适的索引类型**：根据数据类型和查询需求选择合适的索引类型。例如，对于字符串类型的列，可以使用前缀索引（Prefix Index）来减少索引占用的空间。对于地理空间数据，可以使用空间索引（Spatial Index）来提高查询性能。

7. **考虑使用覆盖索引**：覆盖索引（Covering Index）是包含查询中所有需要的列的索引。当查询只需要访问覆盖索引中的列时，数据库可以避免访问实际的数据表，从而提高查询性能。

8. **定期评估和优化索引**：数据库的使用模式和数据分布可能会随着时间的推移而发生变化。因此，建议定期评估和优化索引，以确保它们能够适应当前的查询需求。可以使用数据库提供的工具和命令（如MySQL的`EXPLAIN`命令）来分析查询性能，并根据需要添加、删除或修改索引。

总之，建立索引的原则是在提高查询性能的同时，尽量减少索引对存储和维护的影响。在设计索引策略时，需要根据实际需求和性能考虑进行权衡。

## MySQL 索引优化方式

在 MySQL 中，优化索引是提高查询性能的关键方法之一。以下是一些常见的 MySQL 索引优化方式：

1. **选择合适的列进行索引**：为查询频繁的列创建索引，这样可以加快查询速度。但不要对过多的列创建索引，因为索引会占用额外的存储空间，并且在插入、更新和删除操作时会增加开销。

2. **使用复合索引**：复合索引（也称为多列索引）是基于多个列的值创建的索引。复合索引可以在多列条件查询时提高性能。在创建复合索引时，考虑列在查询中的使用顺序并将最常用的列放在索引的前面。

3. **使用覆盖索引**：覆盖索引是包含查询所需全部列的索引。当查询仅涉及覆盖索引中的列时，MySQL 可以直接从索引中获取数据，而无需访问表本身，从而提高查询性能。考虑在经常一起查询的列上创建覆盖索引。

4. **使用前缀索引**：前缀索引是基于列值的前缀（而非整个列值）创建的索引。前缀索引可以减少索引的大小，并提高查询速度。在创建前缀索引时，选择合适的前缀长度以平衡索引大小和查询性能。

5. **避免使用 SELECT ***：避免在查询中使用 SELECT * 以减少传输和处理的数据量。相反，仅选择需要的列，这样可以更好地利用覆盖索引。

6. **优化 LIKE 查询**：避免在 LIKE 查询中使用以百分号（%）开头的模式，因为这会导致索引失效。如果可能，将百分号（%）放在模式的末尾，以便 MySQL 可以利用索引。

7. **使用 EXPLAIN 分析查询**：使用 EXPLAIN 命令分析查询的执行计划，以了解 MySQL 如何使用索引。根据 EXPLAIN 输出的信息，可以判断是否需要对索引进行优化。

8. **定期维护索引**：定期使用 OPTIMIZE TABLE 命令对表进行优化，以整理索引并释放未使用的空间。此外，可以使用 ANALYZE TABLE 命令更新表的统计信息，以帮助 MySQL 优化器更好地选择索引。

9. **考虑使用索引提示**：在某些情况下，MySQL 优化器可能无法选择最佳的索引。可以使用索引提示（例如 USE INDEX、FORCE INDEX 等）来告诉 MySQL 使用特定的索引。

10. **了解存储引擎的索引特性**：不同的存储引擎（例如 InnoDB、MyISAM 等）具有不同的索引实现和特性。了解所使用的存储引擎的索引特性，并根据这些特性进行优化。

通过上述方法对 MySQL 索引进行优化，可以有效地提高查询性能并减少资源消耗。在实际应用中，需要根据表的结构和查询模式来选择合适的优化策略。

## 什么情况下索引失效?

- - 使用 != 或  <>
  - 类型不一致导致索引失效
  - 函数导致的索引失效, 函数用在索引列时, 不走索引
    ![image-20230730211655859](D:\typora\Golang_Engineer\typora-user-images\image-20230730211655859.png)
  - 运算符导致的索引失效
    ![image-20230730211720109](D:\typora\Golang_Engineer\typora-user-images\image-20230730211720109.png)
  - OR引起的索引失效
    ![image-20230730211745823](D:\typora\Golang_Engineer\typora-user-images\image-20230730211745823.png), 若有INDEX(k), 则不走索引, 如果OR连接的时同一个字段, 则不会失效
  - 模糊查询导致的索引失效
    ![image-20230730211758487](D:\typora\Golang_Engineer\typora-user-images\image-20230730211758487.png), %放字符串字段前匹配不走索引
  - NOT IN, NOT EXISTS导致索引失效

在某些情况下，数据库可能无法使用索引来优化查询，导致索引失效。以下是一些可能导致索引失效的情况：

1. **使用函数或表达式**：在查询条件中对索引列使用函数或表达式可能导致索引失效。这是因为数据库无法直接比较函数或表达式的结果与索引值。例如，`SELECT * FROM users WHERE LOWER(username) = 'john_doe'`。

2. **隐式类型转换**：如果查询条件中的数据类型与索引列的数据类型不匹配，可能导致隐式类型转换，从而使索引失效。为避免这种情况，确保查询条件中的数据类型与索引列的数据类型一致。

3. **使用OR条件**：在查询条件中使用OR条件连接多个列可能导致索引失效。这是因为数据库在处理OR条件时可能无法同时使用多个索引。例如，`SELECT * FROM users WHERE username = 'john_doe' OR email = 'john@example.com'`。为解决这个问题，可以考虑使用UNION查询代替OR条件。

4. **使用%前导通配符**：在使用LIKE操作符进行模糊搜索时，如果使用%作为前导通配符，可能导致索引失效。这是因为数据库无法确定搜索字符串的起始位置，从而无法使用索引进行优化。例如，`SELECT * FROM users WHERE username LIKE '%doe'`。

5. **不等式操作符**：在某些情况下，使用不等于（<>）操作符可能导致索引失效。这是因为数据库可能无法有效地使用索引来过滤不等于给定值的记录。

6. **复合索引列顺序**：在使用复合索引时，查询条件中的列顺序与复合索引中的列顺序不一致可能导致索引失效。为避免这种情况，确保查询条件中的列顺序与复合索引中的列顺序一致。

7. **索引选择性较低**：如果索引的选择性较低（即索引列的唯一值占总记录数的比例较低），数据库可能会选择全表扫描而不是使用索引来执行查询。这是因为全表扫描在这种情况下可能比使用低选择性的索引更有效。

8. **查询优化器的决策**：查询优化器可能会基于统计信息、表大小和其他因素来决定是否使用索引。在某些情况下，查询优化器可能认为全表扫描或其他方法比使用索引更有效。这种情况下，索引可能被认为是失效的。

要解决索引失效的问题，可以根据具体情况调整查询语句，确保数据库能够有效地使用索引来优化查询。同时，定期更新数据库统计信息，以帮助查询优化器做出更准确的决策。

## MySQL单表不要超过2000W行，靠谱吗？

- MySQL 的表数据是以页的形式存放的，页在磁盘中不一定是连续的。
- 页的空间是 16K, 并不是所有的空间都是用来存放数据的，会有一些固定的信息，如，页头，页尾，页码，校验码等等。
- 在 B+ 树中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。
- 索引结构不会影响单表最大行数，2000W 也只是推荐值，超过了这个值可能会导致 B + 树层级更高，影响查询性能。

MySQL 单表行数的上限取决于多个因素，如硬件资源、存储引擎、表结构和查询性能等。因此，是否靠谱要根据具体情况来判断。

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

在实际生产环境中，有许多 MySQL 单表存储了超过 2000W（即 2000 万）行的记录。然而，在大量数据的情况下，查询和维护性能可能会受到影响。为了避免性能瓶颈，通常采用如下策略：

1. **优化索引**：为表中的查询频繁的列创建合适的索引，以提高查询性能。合理使用覆盖索引（Covering Index）和前缀索引（Prefix Index）可以帮助减少磁盘 I/O 和内存使用。

2. **分区表**：MySQL 支持表分区，将一个大表划分为多个独立的子表。这样，查询时只需要扫描相关的子表，而不是整个大表。分区表可以根据不同的分区方法（例如按照范围、列表、哈希等）进行划分。

3. **垂直拆分**：将一个大表按照列进行拆分，将不常用的列或者较大的列单独存储在一个或多个新表中。这样，查询时只需要访问所需列的数据，减少 I/O 和内存使用。

4. **水平拆分**：将一个大表按照行进行拆分，将记录分布到多个子表中。这可以通过分布式数据库或者应用层的数据分片（Sharding）实现。通过水平拆分，能够更好地利用硬件资源，提高查询性能。

5. **硬件升级**：提升服务器的硬件配置，如内存、磁盘和 CPU 等，可以缓解由于大量数据导致的性能问题。

综上所述，MySQL 单表存储 2000W 行记录是可以实现的，但在实际应用中需要根据系统的需求和性能要求进行权衡。如果可能，采用上述策略进行优化，以保持良好的查询和维护性能。

## MySQL 使用 like “%x“，索引一定会失效吗？

是的，当你在 MySQL 中使用 LIKE 语句并且模式以百分号（%）开头时，索引通常会失效。这是因为以百分号开头的模式表示任意长度和任意字符的前缀，MySQL 无法在索引中找到特定的起始位置来进行搜索。

## InnoDB与MYISAM区别

InnoDB 和 MyISAM 是两种常见的存储引擎，用于 MySQL 数据库管理系统。它们在设计和性能特性上有一些重要的区别。以下是 InnoDB 和 MyISAM 的主要区别：

1. **事务支持**：
   - InnoDB 支持事务（ACID特性：原子性、一致性、隔离性、持久性），这意味着它可以确保数据的一致性和完整性，并允许您使用 `BEGIN`、`COMMIT` 和 `ROLLBACK` 来处理事务。
   - MyISAM 不支持事务，因此不具备事务的 ACID 特性。
2. **并发控制**：
   - InnoDB 使用行级锁（row-level locking）来实现并发控制，这使得多个事务可以并行处理，提高了并发性能。
   - MyISAM 使用表级锁（table-level locking），这意味着当一个事务锁定了一张表中的某一行，其他事务无法同时操作整个表，这可能导致性能瓶颈。
3. **外键约束**：
   - InnoDB 支持外键约束，可以确保数据的引用完整性，并在关联表之间建立引用关系。
   - MyISAM 不支持外键约束，因此不具备这种数据完整性保护。
4. **崩溃恢复**：
   - InnoDB 具有崩溃恢复功能，可以在数据库崩溃后自动恢复数据。
   - MyISAM 需要手动执行 `REPAIR TABLE` 命令来修复崩溃的表，可能会导致数据丢失。
5. **索引类型**：
   - InnoDB 使用聚簇索引（clustered index）作为主键索引，表数据实际上按照主键的顺序存储，这对于查询性能有一定的优势。
   - MyISAM 使用非聚簇索引，主键索引和数据存储在不同的位置，这可能导致查询性能较差。
6. **全文搜索**：
   - MyISAM 支持全文搜索索引，使得它在全文搜索应用中有一定的优势。
   - InnoDB 从 MySQL 5.6 版本开始支持全文搜索索引，但 MyISAM 仍然在这方面具有一定的优势。
7. **空间数据类型**：
   - InnoDB 支持空间数据类型（GIS），用于存储地理信息数据。
   - MyISAM 不支持空间数据类型。
8. **锁定级别**：
   - InnoDB 支持不同的锁定级别，包括读未提交、读已提交、可重复读和串行化。
   - MyISAM 只支持表级锁定。

根据应用程序的需求，您可以选择使用 InnoDB 或 MyISAM 存储引擎。通常情况下，如果需要事务支持、并发控制和数据完整性保护，InnoDB 是更好的选择。而如果只需要简单的读写操作和全文搜索功能，MyISAM 可能是一个合适的选项。此外，最新版本的 MySQL 也支持其他存储引擎，如存储过程和函数的 Memory 存储引擎、全文搜索的 Elasticsearch 存储引擎等，您可以根据具体需求选择合适的存储引擎。
